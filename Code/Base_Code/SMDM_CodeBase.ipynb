{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SMDM_CodeBase.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5DA7c0VKSYX"
      },
      "source": [
        "**Sarcasm Target Detection Codebase**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCkgewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwogICAgICBwZXJjZW50LnRleHRDb250ZW50ID0KICAgICAgICAgIGAke01hdGgucm91bmQoKHBvc2l0aW9uIC8gZmlsZURhdGEuYnl0ZUxlbmd0aCkgKiAxMDApfSUgZG9uZWA7CiAgICB9CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "f_dmEBsSBf8M",
        "outputId": "84ef7a9a-3c55-4079-861e-de483a634125"
      },
      "source": [
        "# Upload 'snippets.xlsx' from the local file system.\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e4c13cf7-2e53-4884-9cb8-6d1a846df29a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e4c13cf7-2e53-4884-9cb8-6d1a846df29a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving snippets.xlsx to snippets.xlsx\n",
            "User uploaded file \"snippets.xlsx\" with length 28003 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lu-Fvr38C2Ho",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "511f7c1e-e0af-49f4-f128-b783a0f325d7"
      },
      "source": [
        "# Mount google drive to use 'crawl-300d-2M.vec'. \n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0EM5zoFdT35O",
        "outputId": "20196a24-f578-47e0-a063-9ba7cc752bb5"
      },
      "source": [
        "!pip install empath"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting empath\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d2/84/a5de61a99252f60d705d7982b3648db517a704c89fa7629d3d3637a6e604/empath-0.89.tar.gz (57kB)\n",
            "\r\u001b[K     |█████▊                          | 10kB 9.4MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 20kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 30kB 10.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 40kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 51kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 3.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from empath) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->empath) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->empath) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->empath) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->empath) (3.0.4)\n",
            "Building wheels for collected packages: empath\n",
            "  Building wheel for empath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for empath: filename=empath-0.89-cp37-none-any.whl size=57824 sha256=7967213559eb4c0c2d755cba234922fa1ab3e7779932db655b243fda80397895\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/ea/2f/2bc54d4f9985ce61753ebc5b00cb2df51d855589267c667308\n",
            "Successfully built empath\n",
            "Installing collected packages: empath\n",
            "Successfully installed empath-0.89\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LweGufCtKzba"
      },
      "source": [
        "# Import basic maths and processing libraries.\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from keras.layers import Dense ,LSTM,concatenate,Input,Flatten\n",
        "from keras.models import Model\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "from nltk.tag import StanfordPOSTagger\n",
        "from nltk.tag import StanfordNERTagger\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from empath import Empath\n",
        "\n",
        "import pickle\n",
        "import codecs\n",
        "from collections import deque"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2npgiN0QQNS"
      },
      "source": [
        "# Excel file contains no header column and names gives custom column names\n",
        "df = pd.read_excel(\"snippets.xlsx\", sheet_name=None, header=None, names=['Snippet','target'])\n",
        "df = df['Sheet1']\n",
        "embedding_file = '/gdrive/MyDrive/crawl-300d-2M.vec'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggbf5YYgjyQI"
      },
      "source": [
        "# Removes all non-alpha numeric characters except ',' from a given strring\n",
        "def clearLine(line):\n",
        "  cleanedLine = ''\n",
        "  for letter in line:\n",
        "    if letter == '?' or letter == '!' or letter == ',' or letter == '\"' or letter == '-' or letter == ';' or letter == '.' or ord(letter) > 255 :\n",
        "      cleanedLine += ' '\n",
        "    else:\n",
        "      cleanedLine += letter\n",
        "  return cleanedLine"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQlSp4C5TtL1"
      },
      "source": [
        "# Load pre-trained fasttext word embedding from the file\n",
        "def loadEmbed():\n",
        "    print('loading word embeddings...')\n",
        "    embeddings_index = {}\n",
        "    f = codecs.open(embedding_file, encoding='utf-8')\n",
        "    for line in f:\n",
        "        # Line has the format : Word val1 val2 val3 ..... val300\n",
        "        values = line.rstrip().rsplit(' ')\n",
        "        word = values[0]\n",
        "        coefs = np.asarray(values[1:], dtype='float32')\n",
        "        embeddings_index[word] = coefs\n",
        "    f.close()\n",
        "    print('found %s word vectors' % len(embeddings_index))\n",
        "    return embeddings_index"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cv6yMkNMgP9u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0154c15f-7404-44d4-a2ac-640d185a51d9"
      },
      "source": [
        "# Loading pre-trained embeddings\n",
        "model=loadEmbed()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading word embeddings...\n",
            "found 1999996 word vectors\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPext8rQigyp"
      },
      "source": [
        "# Stores all distinct words in the dataset.\n",
        "all_words=[]\n",
        "\n",
        "# Extract all poosible words in the dataset\n",
        "for i in range(len(df['Snippet'])):\n",
        "    line = clearLine(df['Snippet'][i])\n",
        "    all_words.extend(line.split())\n",
        "\n",
        "# get all unique words from the dataset\n",
        "all_words=list(dict.fromkeys(all_words))\n",
        "\n",
        "# make all words to lowercase\n",
        "all_words=[x.lower() for x in all_words]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yC4I9QzPiomu"
      },
      "source": [
        "# Stores the vector representations of the words from the dataset.\n",
        "embeddings={}\n",
        "for each in all_words:\n",
        "    # Get vectors for words in the dataset\n",
        "    if each not in model.keys(): \n",
        "        embeddings[each]=model['unk']\n",
        "    else:\n",
        "        embeddings[each]=model[each]\n",
        "\n",
        "# make <pad> as the 0-vector\n",
        "embeddings['<pad>'] = [0]*300\n",
        "# make <start> token to start vector\n",
        "embeddings['<start>'] = model[\"start\"]\n",
        "# make <end> token to end vector \n",
        "embeddings['<end>'] = model[\"end\"]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FzhEcqOI0Cq"
      },
      "source": [
        "# Prepare the left context, right context, and candidate word from the dataset.\n",
        "# The pre-processed data has the data type string\n",
        "# Pre-Processed Data (ppd)\n",
        "\n",
        "ppd = {}\n",
        "ppd['left_context'] = []\n",
        "ppd['right_context'] = []\n",
        "ppd['Candidate_word'] = []\n",
        "ppd['target_status'] = []\n",
        "\n",
        "for i in range(len(df['Snippet'])):\n",
        "  # clean the line and split the line into individual words\n",
        "  line = clearLine(df['Snippet'][i].lower());\n",
        "  line = line.split()\n",
        "  # get each individual word in sarcasm target to identify possible sarcasm\n",
        "  # target words in the sentence\n",
        "  targetList = df['target'][i].lower().split(\",\")\n",
        "  targetWord = []\n",
        "  for tl in targetList:\n",
        "    targetWord.extend(tl.split())\n",
        "  \n",
        "  # Choosing each word in the sentence as candidate word, extract the left context,\n",
        "  # right context and the target label.\n",
        "  for i in range(len(line)):\n",
        "    word = line[i]\n",
        "    ppd['Candidate_word'].append(word)\n",
        "    ppd['left_context'].append([\"<start>\"] + line[:i])\n",
        "    ppd['right_context'].append(line[i+1:] + [\"<end>\"])\n",
        "    ppd['target_status'].append(int(word in targetWord))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ov65vnKME1Wv"
      },
      "source": [
        "# Embedding Left Context\n",
        "# Convert each word in left context into vector representation to be used as input \n",
        "keras_left_context = []\n",
        "for i in range(len(ppd['left_context'])):\n",
        "    one_vector = []\n",
        "    temp = ppd['left_context'][i]\n",
        "    for m in temp:\n",
        "        one_vector.append(embeddings[m])\n",
        "    one_vector.extend([embeddings['<pad>'] for x in range(78 - len(ppd['left_context'][i]))])\n",
        "    keras_left_context.append(one_vector)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjUxOeBUH49B"
      },
      "source": [
        "# Embedding Right Context \n",
        "# Convert each word in right context into vector representation to be used as input \n",
        "keras_right_context = []\n",
        "for i in range(len(ppd['right_context'])):\n",
        "    one_vector = []\n",
        "    temp = ppd['right_context'][i]\n",
        "    for m in temp:\n",
        "        one_vector.append(embeddings[m])\n",
        "    one_vector.extend([embeddings['<pad>'] for x in range(78 - len(ppd['right_context'][i]))])\n",
        "    keras_right_context.append(one_vector)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5ehP344Ic1y"
      },
      "source": [
        "# Embedding Candidate Word\n",
        "# Convert each candidate word into vector representation to be used as input \n",
        "keras_middle = []\n",
        "for i in range(len(ppd['Candidate_word'])):\n",
        "    keras_middle.append(embeddings[ppd['Candidate_word'][i]])\n",
        "\n",
        "labels = ppd['target_status']"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Won77S-7IypK"
      },
      "source": [
        "#Saving the processed dataset in a pickle file\n",
        "# f = open(b\"Data_fast.pkl\",\"wb\")\n",
        "# pickle.dump(zip(keras_left_context,keras_right_context,keras_middle,ppd['target_status']),f)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62vxErvmRAFA"
      },
      "source": [
        "Socio-Linguistic Feature Extraction\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17MyiJkvRG6u"
      },
      "source": [
        "# create an object of one hot encoder\n",
        "ohe=OneHotEncoder()\n",
        "# create an object of label encoder\n",
        "lb=LabelEncoder()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ColM0MMZRMAo",
        "outputId": "a9558d47-1c9d-4916-92d0-43f97044bc8e"
      },
      "source": [
        "# Using Stanford POS Tagger API\n",
        "jar = '/gdrive/MyDrive/features/stanford-postagger-3.9.2.jar'\n",
        "model = '/gdrive/MyDrive/features/english-left3words-distsim.tagger'\n",
        "pos_tagger = StanfordPOSTagger(model, jar, encoding='utf8')\n",
        "\n",
        "# Extracting POS Features\n",
        "POS_snippets=[]\n",
        "for i in range(len(df['Snippet'])):\n",
        "    # get pos tags for all words in the sentence. \n",
        "    POS_snippets.extend(pos_tagger.tag(clearLine(df['Snippet'][i]).lower().split()))\n",
        "POS_snippets_type=[x[1] for x in POS_snippets]\n",
        "POS_snippets_type=lb.fit_transform(POS_snippets_type)\t\n",
        "pos_vec=ohe.fit_transform(np.reshape(POS_snippets_type,(-1, 1)))\n",
        "pos_vec=pos_vec.todense()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/tag/stanford.py:149: DeprecationWarning: \n",
            "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
            "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
            "  super(StanfordPOSTagger, self).__init__(*args, **kwargs)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1go53RTPRMev",
        "outputId": "c9edc029-4efb-4b79-eeab-88aba88a31ed"
      },
      "source": [
        "# Using Stanford NER Tagger API\n",
        "jar_n = '/gdrive/MyDrive/features/stanford-ner-3.9.2.jar'\n",
        "model_n = '/gdrive/MyDrive/features/english.all.3class.distsim.crf.ser.gz'\n",
        "ner_tagger = StanfordNERTagger(model_n, jar_n, encoding='utf8')\n",
        "\n",
        "# Extracting NER Features\n",
        "ner_snippets=[]\n",
        "for i in range(len(df['Snippet'])):\n",
        "    # get ner tags for all words in the sentence\n",
        "    ner_snippets.extend(ner_tagger.tag(clearLine(df['Snippet'][i]).lower().split()))\n",
        "ner_snippets_type=[x[1] for x in ner_snippets]\n",
        "ner_snippets_type=lb.fit_transform(ner_snippets_type)\t\n",
        "ner_vec=ohe.fit_transform(np.reshape(ner_snippets_type,(-1, 1)))\n",
        "ner_vec=ner_vec.todense()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/tag/stanford.py:183: DeprecationWarning: \n",
            "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
            "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
            "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UE3JWgnYRNMu"
      },
      "source": [
        "# Extracting Empath Features\n",
        "lexicon = Empath()\n",
        "empath_vec=[]\n",
        "for text in ppd['Candidate_word']:\n",
        "    a=lexicon.analyze(text, normalize=True)\n",
        "    bv=[]\n",
        "    for i in a.values():\n",
        "        bv.append(i)\n",
        "    empath_vec.append(bv)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28iw-AYwJCHr"
      },
      "source": [
        "Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iN1wcrRWKt8E"
      },
      "source": [
        "# Function to group together candidate-words belonging to the same line.\n",
        "def compress():\n",
        "    lengths = []\n",
        "    for i in range (1,len(ppd['left_context'])):\n",
        "        # If left context contains only '<start>'\n",
        "        if len(ppd['left_context'][i]) == 1:\n",
        "            lengths.append(i)\n",
        "    lengths.append(len(ppd['left_context']))\n",
        "    compressor = []\n",
        "    compressor.append(range(lengths[0]))\n",
        "    for i in range (1,len(lengths)):\n",
        "        compressor.append(range(lengths[i-1],lengths[i]))\n",
        "    return compressor"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNWYsrPpP0es"
      },
      "source": [
        "comp = compress()"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUUEUouCNQmb"
      },
      "source": [
        "# Training Data, Test Data Preparation\n",
        "\n",
        "def prep (train_indices, test_indices):\n",
        "    print (len(train_indices), len(test_indices))\n",
        "\n",
        "    # Ungroup training dataset candidate-words belonging to the same line.\n",
        "    train_ids = []\n",
        "    for i in range(len(train_indices)):\n",
        "        train_ids.extend(comp[train_indices[i]])\n",
        "\n",
        "    # Ungroup testing dataset candidate-words belonging to the same line.\n",
        "    test_ids = []\n",
        "    for i in range(len(test_indices)):\n",
        "        test_ids.extend(comp[test_indices[i]])\n",
        "\n",
        "    # Training Data Preparation\n",
        "    train_left   = []\n",
        "    train_right  = []\n",
        "    train_middle = []\n",
        "    train_labels = []\n",
        "    train_pos_vec= []\n",
        "    train_ner_vec= []\n",
        "    train_empath_vec=[]\n",
        "\n",
        "    for id in train_ids:\n",
        "        train_left.append(keras_left_context[id])\n",
        "        train_right.append(keras_right_context[id])\n",
        "        train_middle.append(keras_middle[id])\n",
        "        train_labels.append(labels[id])\n",
        "        train_pos_vec.append(pos_vec[id])\n",
        "        train_ner_vec.append(ner_vec[id])\n",
        "        train_empath_vec.append(empath_vec[id])\n",
        "\n",
        "    train_left   = np.array(train_left)\n",
        "    train_right  = np.array(train_right)\n",
        "    train_middle = np.array(train_middle)\n",
        "    train_labels = np.array(train_labels)\n",
        "    train_middle = np.expand_dims(train_middle,axis=1)\n",
        "    train_pos_vec= np.array(train_pos_vec)\n",
        "    train_ner_vec= np.array(train_ner_vec)\n",
        "    train_empath_vec= np.array(train_empath_vec)\n",
        "\n",
        "    # Testing Data Preparation\n",
        "    val_left   = []\n",
        "    val_right  = []\n",
        "    val_middle = []\n",
        "    val_labels = []\n",
        "    val_pos_vec= []\n",
        "    val_ner_vec= []\n",
        "    val_empath_vec=[]\n",
        "\n",
        "    for id in test_ids:\n",
        "        val_left.append(keras_left_context[id])\n",
        "        val_right.append(keras_right_context[id])\n",
        "        val_middle.append(keras_middle[id])\n",
        "        val_labels.append(labels[id])\n",
        "        val_pos_vec.append(pos_vec[id])\n",
        "        val_ner_vec.append(ner_vec[id])\n",
        "        val_empath_vec.append(empath_vec[id])\n",
        "\n",
        "    val_left   = np.array(val_left)\n",
        "    val_right  = np.array(val_right)\n",
        "    val_middle = np.array(val_middle)\n",
        "    val_labels = np.array(val_labels)\n",
        "    val_middle = np.expand_dims(val_middle, axis=1)\n",
        "    val_pos_vec=np.array(val_pos_vec)\n",
        "    val_ner_vec=np.array(val_ner_vec)\n",
        "    val_empath_vec=np.array(val_empath_vec)\n",
        "\n",
        "    # Below part only for TD lstm\n",
        "    if mode == 'TD':\t    \n",
        "      train_left = np.concatenate((train_left, train_middle), axis=1)\n",
        "      train_right = np.concatenate((train_middle, train_right), axis=1)\n",
        "      val_left = np.concatenate((val_left, val_middle), axis=1)\n",
        "      val_right = np.concatenate((val_middle, val_right), axis=1)\n",
        "\n",
        "    return(train_left,train_right,train_middle,train_pos_vec,train_ner_vec,train_empath_vec,train_labels,val_left,val_right,val_middle,val_pos_vec,val_ner_vec,val_empath_vec,val_labels)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34X2_lDDA-FB"
      },
      "source": [
        "def de_comp(arr, test_indices):\n",
        "    arr = deque(arr)\n",
        "    fin = []\n",
        "    for i in test_indices:\n",
        "        temp = []\n",
        "        for j in range(len(comp[i])):\n",
        "            temp.append(arr.popleft())\n",
        "        fin.append(temp)\n",
        "    return (fin)    "
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYk7ipoiBF43"
      },
      "source": [
        "def accuracy (pred, labels, test_indices):\n",
        "    pred = pred[0]\n",
        "    num_sent = len(comp)\n",
        "    num_words = len(pred)\n",
        "    threshold = 0\n",
        "    cnt = 0\n",
        "    # Threshold calculation for binary classification problem\n",
        "    for a,b in zip (pred,labels):\n",
        "        if b==1.0:\n",
        "            threshold+=a\n",
        "            cnt+=1\n",
        "    threshold = threshold.item()/cnt\n",
        "\n",
        "    pred_th = []\n",
        "    for x in pred:\n",
        "        if (x<=threshold):\n",
        "            pred_th.append(0)\n",
        "        else :\n",
        "            pred_th.append(1)\n",
        "\n",
        "    pred_th = np.array(pred_th)\n",
        "    print (\"Number of Test sentences : {}\".format(len(test_indices)))\n",
        "    error = pred_th-labels\n",
        "    error_d  = de_comp(error,test_indices)\n",
        "    labels_d = de_comp(labels,test_indices)\n",
        "    pred_d   = de_comp(pred_th,test_indices)\n",
        "    em_cnt = 0\n",
        "    ds_cnt = 0\n",
        "    mic_f1 = 0\n",
        "\n",
        "    for err in error_d:\n",
        "        if (sum(err)==0):\n",
        "           em_cnt += 1\n",
        "        ds_cnt += float(len(err)-sum(np.abs(err)))/len(err)\n",
        "\n",
        "    for lab, pre in zip(labels_d,pred_d):\n",
        "\n",
        "        tp = 0\n",
        "        fp = 0\n",
        "        fn = 0\n",
        "        tn = 0\n",
        "              \n",
        "        for i,j in zip(lab,pre):\n",
        "            if (int(i) == 1)  and (int(j) ==0) :\n",
        "                fn += 1\n",
        "            elif (int(i) == 0)  and (int(j) ==1) :\n",
        "                fp += 1\n",
        "            elif (int(i) == 0)  and (int(j) ==0) :\n",
        "                tn += 1\n",
        "            elif (int(i) == 1) and (int(j) ==1):\n",
        "                tp += 1\n",
        "        try : \n",
        "            mic_f1 += float(2*tp) / (2*tp + fn +fp)\n",
        "        except :\n",
        "            pass\n",
        "\n",
        "    TP=0\n",
        "    TN=0\n",
        "    FP=0\n",
        "    FN=0\n",
        "    for a,b in zip(labels, pred_th):\n",
        "\n",
        "        if int(a)==0 and b==0:\n",
        "            TN+=1\n",
        "        if int(a)==1 and b==1:\n",
        "            TP+=1\n",
        "        if int(a)==0 and b==1:\n",
        "            FP+=1\n",
        "        if int(a)==1 and b==0:\n",
        "            FN+=1 \n",
        "    print (\"TP = {}, TN = {},FP = {}, FN = {}\".format(TP,TN,FP,FN))\n",
        "    F1 = float(2*TP)/(2*TP + FP+ FN)\n",
        "    EM = float(em_cnt)/len(test_indices)\n",
        "    DS = float(ds_cnt)/len(test_indices)\n",
        "    uF1= float(mic_f1)/len(test_indices)\n",
        "    print (\"EM Accuracy : {}\".format(EM))\n",
        "    print (\"DS Accuracy : {}\".format(DS))\n",
        "    print (\"Micro F1    : {}\".format(uF1))\n",
        "    print (\"Macro F1 Score = {}\".format(F1))\n",
        "    return (pred_d, labels_d)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWC-tUwcAJx3"
      },
      "source": [
        "# Tuned-Hyper Parameters\n",
        "embed_size = 1024\n",
        "hidden_size = 32\n",
        "num_epochs=30\n",
        "layer_size = 16\n",
        "batch_size = 64\n",
        "\n",
        "# 'Uni' : Unidirectional LSTM  |  'Bi' : Bidirectional LSTM  | 'TD' : Target-dependent LSTM\n",
        "mode = 'Uni' \n",
        "# Use speech features while concatenating in dense layer if True else ignore\n",
        "augmentation = False"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZkaHjZN1IPM"
      },
      "source": [
        "# Define the model and run the model for given epochs\n",
        "def model(train_l,train_r,train_m,train_pos,train_ner,train_empath,train_labels,test_l,test_r,test_m,test_pos,test_ner,test_empath,test_labels,test_indices):\n",
        "    # Create placeholder for each input type to define the model\n",
        "    x=Input(shape=(78, 300))\n",
        "    y=Input(shape=(78, 300))\n",
        "    z=Input(shape=(1, 300))\n",
        "    z1=Input(shape=([1,34]))\n",
        "    z2=Input(shape=([1,2]))\n",
        "    # z3=Input(shape=([64]))\n",
        "    z4=Input(shape=([194]))\n",
        "\n",
        "    if mode == 'Bi':\n",
        "      # Define birectional layer on LSTM and use concat as the merge mode.\n",
        "    \tleft_out=Bidirectional(LSTM(hidden_size//2,return_sequences=False),input_shape=(train_l.shape[1:]))(x)      \n",
        "    \tmiddle = Bidirectional(LSTM(hidden_size//2,return_sequences=False),input_shape=(train_m.shape[1:]))(z)\n",
        "    \tright_out=Bidirectional(LSTM(hidden_size//2,return_sequences=False),input_shape=(train_r.shape[1:]))(y)\n",
        "\n",
        "    else:\n",
        "      # Define LSTM units\n",
        "    \tleft_out  = LSTM(hidden_size,return_sequences=False)(x)\n",
        "    \tmiddle    = LSTM(hidden_size,return_sequences=False)(z)\n",
        "    \tright_out = LSTM(hidden_size,return_sequences=False)(y)\n",
        "\n",
        "    pos_dense=Dense(32,activation='relu')(z1)\n",
        "    ner_dense=Dense(16,activation='relu')(z2)\n",
        "    # liwc_dense=Dense(64,activation='relu')(z3)\n",
        "    empath_dense=Dense(64,activation='relu')(z4)\n",
        "\n",
        "    if mode == 'TD' and augmentation == False :\n",
        "      out=concatenate([left_out,right_out],axis=-1)\n",
        "\n",
        "    if mode == 'TD' and augmentation == True :\n",
        "    \tout=concatenate([left_out,right_out,pos_dense,ner_dense,empath_dense],axis=-1)\n",
        "\n",
        "    if mode != 'TD' and augmentation == False :\n",
        "      out=concatenate([left_out,middle,right_out],axis=-1)\n",
        "\n",
        "    if mode != 'TD' and augmentation == True :\n",
        "    \tout=concatenate([left_out,middle,right_out,pos_dense,ner_dense,empath_dense],axis=-1)\n",
        "\n",
        "    out=Dense(layer_size, activation='relu')(out)\n",
        "    output=Dense(1, activation='sigmoid')(out)\n",
        "    model = Model(inputs=[x,y,z,z1,z2,z4], outputs=output)\n",
        "    model.compile(optimizer=Adam(lr=10e-5),loss='binary_crossentropy',metrics=['accuracy'])\n",
        "    print (\"Starting Epochs\")\n",
        "    for i in range(num_epochs):\n",
        "        model.fit([train_l,train_r,train_m,train_pos,train_ner,train_empath],train_labels,batch_size=batch_size, epochs=1,verbose=0)\n",
        "        print('***************************************************************')\n",
        "        print (\"predicting_ Epoch : {}\".format(i))\n",
        "        pred_val=[]\n",
        "        pred_val.append(model.predict([test_l,test_r,test_m,test_pos,test_ner,test_empath]))\n",
        "        pre_d, lab_d = accuracy (pred_val, test_labels,test_indices)\n",
        "\n",
        "        # with open('Tweets Aug-{}.csv'.format(i), mode='w') as file:\n",
        "        #     file_writer = csv.writer(file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
        "        #     for a,b in zip (pre_d,lab_d):\n",
        "        #         file_writer.writerow([a,b])\n",
        "    return model"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFHCUy5jLV2e"
      },
      "source": [
        "# Dataset division for 3-fold cross validation\n",
        "indices = list(range(len(comp)))\n",
        "np.random.shuffle(indices)\n",
        "bins = []\n",
        "bins.append(indices[:int(0.33*len(indices))])\n",
        "bins.append(indices[int(0.33*len(indices)):int(0.66*len(indices))])\n",
        "bins.append(indices[int(0.66*len(indices)):])"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6hjPEsuN-33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4e51dc6-4a55-4004-e07b-7b32729d7516"
      },
      "source": [
        "for i in range (3):\n",
        "    print (\"Fold {}\".format(i+1))\n",
        "    print (len(bins[0] + bins[1]),len(bins[2]))\n",
        "    train_left,train_right,train_middle,pos_vec_train,ner_vec_train,empath_vec_train,train_labels,val_left,val_right,val_middle,pos_vec_val,ner_vec_val,empath_vec_val,val_labels = prep (bins[i%3] + bins[(i+1)%3], bins[(i+2)%3])\n",
        "    Sar_model=model(train_left,train_right,train_middle,pos_vec_train,ner_vec_train,empath_vec_train,train_labels,val_left,val_right,val_middle,pos_vec_val,ner_vec_val,empath_vec_val,val_labels,bins[(i+2)%3])\n",
        "    Sar_model.save_weights(\"Bert Tweets Aug.h5\")\n",
        "    print(\"Saved model to disk\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold 1\n",
            "147 77\n",
            "147 77\n",
            "Starting Epochs\n",
            "***************************************************************\n",
            "predicting_ Epoch : 0\n",
            "Number of Test sentences : 77\n",
            "TP = 103, TN = 862,FP = 963, FN = 123\n",
            "EM Accuracy : 0.025974025974025976\n",
            "DS Accuracy : 0.46161238374129027\n",
            "Micro F1    : 0.18036747172988668\n",
            "Macro F1 Score = 0.15944272445820434\n",
            "***************************************************************\n",
            "predicting_ Epoch : 1\n",
            "Number of Test sentences : 77\n",
            "TP = 117, TN = 1274,FP = 551, FN = 109\n",
            "EM Accuracy : 0.03896103896103896\n",
            "DS Accuracy : 0.5077537325953293\n",
            "Micro F1    : 0.20269052062279017\n",
            "Macro F1 Score = 0.26174496644295303\n",
            "***************************************************************\n",
            "predicting_ Epoch : 2\n",
            "Number of Test sentences : 77\n",
            "TP = 98, TN = 1056,FP = 769, FN = 128\n",
            "EM Accuracy : 0.012987012987012988\n",
            "DS Accuracy : 0.5125240043287679\n",
            "Micro F1    : 0.18477120700496544\n",
            "Macro F1 Score = 0.17932296431838976\n",
            "***************************************************************\n",
            "predicting_ Epoch : 3\n",
            "Number of Test sentences : 77\n",
            "TP = 118, TN = 1253,FP = 572, FN = 108\n",
            "EM Accuracy : 0.012987012987012988\n",
            "DS Accuracy : 0.6165868518426799\n",
            "Micro F1    : 0.25044027729300256\n",
            "Macro F1 Score = 0.2576419213973799\n",
            "***************************************************************\n",
            "predicting_ Epoch : 4\n",
            "Number of Test sentences : 77\n",
            "TP = 120, TN = 1424,FP = 401, FN = 106\n",
            "EM Accuracy : 0.03896103896103896\n",
            "DS Accuracy : 0.7064060228456537\n",
            "Micro F1    : 0.31125171084259984\n",
            "Macro F1 Score = 0.321285140562249\n",
            "***************************************************************\n",
            "predicting_ Epoch : 5\n",
            "Number of Test sentences : 77\n",
            "TP = 122, TN = 1508,FP = 317, FN = 104\n",
            "EM Accuracy : 0.09090909090909091\n",
            "DS Accuracy : 0.7435650414957995\n",
            "Micro F1    : 0.3484773315087737\n",
            "Macro F1 Score = 0.3669172932330827\n",
            "***************************************************************\n",
            "predicting_ Epoch : 6\n",
            "Number of Test sentences : 77\n",
            "TP = 106, TN = 1606,FP = 219, FN = 120\n",
            "EM Accuracy : 0.11688311688311688\n",
            "DS Accuracy : 0.7798841715581695\n",
            "Micro F1    : 0.3565607552620539\n",
            "Macro F1 Score = 0.38475499092558985\n",
            "***************************************************************\n",
            "predicting_ Epoch : 7\n",
            "Number of Test sentences : 77\n",
            "TP = 93, TN = 1684,FP = 141, FN = 133\n",
            "EM Accuracy : 0.18181818181818182\n",
            "DS Accuracy : 0.831681190868973\n",
            "Micro F1    : 0.3792986594934647\n",
            "Macro F1 Score = 0.4043478260869565\n",
            "***************************************************************\n",
            "predicting_ Epoch : 8\n",
            "Number of Test sentences : 77\n",
            "TP = 89, TN = 1710,FP = 115, FN = 137\n",
            "EM Accuracy : 0.23376623376623376\n",
            "DS Accuracy : 0.8427926268331724\n",
            "Micro F1    : 0.38028299262065496\n",
            "Macro F1 Score = 0.413953488372093\n",
            "***************************************************************\n",
            "predicting_ Epoch : 9\n",
            "Number of Test sentences : 77\n",
            "TP = 87, TN = 1724,FP = 101, FN = 139\n",
            "EM Accuracy : 0.24675324675324675\n",
            "DS Accuracy : 0.8492489069817967\n",
            "Micro F1    : 0.37863067668262473\n",
            "Macro F1 Score = 0.42028985507246375\n",
            "***************************************************************\n",
            "predicting_ Epoch : 10\n",
            "Number of Test sentences : 77\n",
            "TP = 84, TN = 1735,FP = 90, FN = 142\n",
            "EM Accuracy : 0.2987012987012987\n",
            "DS Accuracy : 0.8513556967133032\n",
            "Micro F1    : 0.37917695580033245\n",
            "Macro F1 Score = 0.42\n",
            "***************************************************************\n",
            "predicting_ Epoch : 11\n",
            "Number of Test sentences : 77\n",
            "TP = 80, TN = 1744,FP = 81, FN = 146\n",
            "EM Accuracy : 0.33766233766233766\n",
            "DS Accuracy : 0.8554358095923084\n",
            "Micro F1    : 0.3830130908052985\n",
            "Macro F1 Score = 0.4134366925064599\n",
            "***************************************************************\n",
            "predicting_ Epoch : 12\n",
            "Number of Test sentences : 77\n",
            "TP = 70, TN = 1763,FP = 62, FN = 156\n",
            "EM Accuracy : 0.2727272727272727\n",
            "DS Accuracy : 0.8597843338787128\n",
            "Micro F1    : 0.3527660651037274\n",
            "Macro F1 Score = 0.39106145251396646\n",
            "***************************************************************\n",
            "predicting_ Epoch : 13\n",
            "Number of Test sentences : 77\n",
            "TP = 75, TN = 1742,FP = 83, FN = 151\n",
            "EM Accuracy : 0.2597402597402597\n",
            "DS Accuracy : 0.8474555759221137\n",
            "Micro F1    : 0.35989825470344944\n",
            "Macro F1 Score = 0.390625\n",
            "***************************************************************\n",
            "predicting_ Epoch : 14\n",
            "Number of Test sentences : 77\n",
            "TP = 71, TN = 1710,FP = 115, FN = 155\n",
            "EM Accuracy : 0.19480519480519481\n",
            "DS Accuracy : 0.8217580080455198\n",
            "Micro F1    : 0.315087748888159\n",
            "Macro F1 Score = 0.3446601941747573\n",
            "***************************************************************\n",
            "predicting_ Epoch : 15\n",
            "Number of Test sentences : 77\n",
            "TP = 72, TN = 1734,FP = 91, FN = 154\n",
            "EM Accuracy : 0.16883116883116883\n",
            "DS Accuracy : 0.8376077910693983\n",
            "Micro F1    : 0.3347941380408913\n",
            "Macro F1 Score = 0.37017994858611825\n",
            "***************************************************************\n",
            "predicting_ Epoch : 16\n",
            "Number of Test sentences : 77\n",
            "TP = 77, TN = 1696,FP = 129, FN = 149\n",
            "EM Accuracy : 0.12987012987012986\n",
            "DS Accuracy : 0.8193261170160057\n",
            "Micro F1    : 0.3247423211708926\n",
            "Macro F1 Score = 0.35648148148148145\n",
            "***************************************************************\n",
            "predicting_ Epoch : 17\n",
            "Number of Test sentences : 77\n",
            "TP = 86, TN = 1638,FP = 187, FN = 140\n",
            "EM Accuracy : 0.16883116883116883\n",
            "DS Accuracy : 0.789874449444096\n",
            "Micro F1    : 0.305425394711109\n",
            "Macro F1 Score = 0.34468937875751504\n",
            "***************************************************************\n",
            "predicting_ Epoch : 18\n",
            "Number of Test sentences : 77\n",
            "TP = 74, TN = 1712,FP = 113, FN = 152\n",
            "EM Accuracy : 0.16883116883116883\n",
            "DS Accuracy : 0.8324532850363606\n",
            "Micro F1    : 0.3305860085080864\n",
            "Macro F1 Score = 0.3583535108958838\n",
            "***************************************************************\n",
            "predicting_ Epoch : 19\n",
            "Number of Test sentences : 77\n",
            "TP = 72, TN = 1737,FP = 88, FN = 154\n",
            "EM Accuracy : 0.16883116883116883\n",
            "DS Accuracy : 0.8434008198392448\n",
            "Micro F1    : 0.33448398643203836\n",
            "Macro F1 Score = 0.37305699481865284\n",
            "***************************************************************\n",
            "predicting_ Epoch : 20\n",
            "Number of Test sentences : 77\n",
            "TP = 76, TN = 1713,FP = 112, FN = 150\n",
            "EM Accuracy : 0.18181818181818182\n",
            "DS Accuracy : 0.8300842307872135\n",
            "Micro F1    : 0.3353704016041678\n",
            "Macro F1 Score = 0.3671497584541063\n",
            "***************************************************************\n",
            "predicting_ Epoch : 21\n",
            "Number of Test sentences : 77\n",
            "TP = 79, TN = 1728,FP = 97, FN = 147\n",
            "EM Accuracy : 0.15584415584415584\n",
            "DS Accuracy : 0.844586009595697\n",
            "Micro F1    : 0.36431317600148766\n",
            "Macro F1 Score = 0.39303482587064675\n",
            "***************************************************************\n",
            "predicting_ Epoch : 22\n",
            "Number of Test sentences : 77\n",
            "TP = 77, TN = 1706,FP = 119, FN = 149\n",
            "EM Accuracy : 0.23376623376623376\n",
            "DS Accuracy : 0.826560918411533\n",
            "Micro F1    : 0.33103635181557256\n",
            "Macro F1 Score = 0.36492890995260663\n",
            "***************************************************************\n",
            "predicting_ Epoch : 23\n",
            "Number of Test sentences : 77\n",
            "TP = 83, TN = 1687,FP = 138, FN = 143\n",
            "EM Accuracy : 0.2077922077922078\n",
            "DS Accuracy : 0.8187905622449507\n",
            "Micro F1    : 0.32659360841179014\n",
            "Macro F1 Score = 0.3713646532438479\n",
            "***************************************************************\n",
            "predicting_ Epoch : 24\n",
            "Number of Test sentences : 77\n",
            "TP = 88, TN = 1688,FP = 137, FN = 138\n",
            "EM Accuracy : 0.22077922077922077\n",
            "DS Accuracy : 0.8246030925473459\n",
            "Micro F1    : 0.37544583843285145\n",
            "Macro F1 Score = 0.3902439024390244\n",
            "***************************************************************\n",
            "predicting_ Epoch : 25\n",
            "Number of Test sentences : 77\n",
            "TP = 82, TN = 1682,FP = 143, FN = 144\n",
            "EM Accuracy : 0.22077922077922077\n",
            "DS Accuracy : 0.8171057532157375\n",
            "Micro F1    : 0.32047881866747213\n",
            "Macro F1 Score = 0.36363636363636365\n",
            "***************************************************************\n",
            "predicting_ Epoch : 26\n",
            "Number of Test sentences : 77\n",
            "TP = 76, TN = 1707,FP = 118, FN = 150\n",
            "EM Accuracy : 0.19480519480519481\n",
            "DS Accuracy : 0.8302194462294378\n",
            "Micro F1    : 0.3354571835091315\n",
            "Macro F1 Score = 0.3619047619047619\n",
            "***************************************************************\n",
            "predicting_ Epoch : 27\n",
            "Number of Test sentences : 77\n",
            "TP = 78, TN = 1703,FP = 122, FN = 148\n",
            "EM Accuracy : 0.2077922077922078\n",
            "DS Accuracy : 0.8300341736893503\n",
            "Micro F1    : 0.3389915279525669\n",
            "Macro F1 Score = 0.36619718309859156\n",
            "***************************************************************\n",
            "predicting_ Epoch : 28\n",
            "Number of Test sentences : 77\n",
            "TP = 85, TN = 1703,FP = 122, FN = 141\n",
            "EM Accuracy : 0.19480519480519481\n",
            "DS Accuracy : 0.8353131134896413\n",
            "Micro F1    : 0.3729711125815023\n",
            "Macro F1 Score = 0.39260969976905313\n",
            "***************************************************************\n",
            "predicting_ Epoch : 29\n",
            "Number of Test sentences : 77\n",
            "TP = 80, TN = 1688,FP = 137, FN = 146\n",
            "EM Accuracy : 0.16883116883116883\n",
            "DS Accuracy : 0.8225858952568551\n",
            "Micro F1    : 0.32428826584670734\n",
            "Macro F1 Score = 0.3611738148984199\n",
            "Saved model to disk\n",
            "Fold 2\n",
            "147 77\n",
            "151 73\n",
            "Starting Epochs\n",
            "***************************************************************\n",
            "predicting_ Epoch : 0\n",
            "Number of Test sentences : 73\n",
            "TP = 125, TN = 1103,FP = 465, FN = 115\n",
            "EM Accuracy : 0.0821917808219178\n",
            "DS Accuracy : 0.686743932509341\n",
            "Micro F1    : 0.29557236118746505\n",
            "Macro F1 Score = 0.30120481927710846\n",
            "***************************************************************\n",
            "predicting_ Epoch : 1\n",
            "Number of Test sentences : 73\n",
            "TP = 125, TN = 974,FP = 594, FN = 115\n",
            "EM Accuracy : 0.0136986301369863\n",
            "DS Accuracy : 0.5637132716290275\n",
            "Micro F1    : 0.240452204420354\n",
            "Macro F1 Score = 0.26068821689259647\n",
            "***************************************************************\n",
            "predicting_ Epoch : 2\n",
            "Number of Test sentences : 73\n",
            "TP = 114, TN = 1105,FP = 463, FN = 126\n",
            "EM Accuracy : 0.0136986301369863\n",
            "DS Accuracy : 0.6580805882427403\n",
            "Micro F1    : 0.2573006480926296\n",
            "Macro F1 Score = 0.27906976744186046\n",
            "***************************************************************\n",
            "predicting_ Epoch : 3\n",
            "Number of Test sentences : 73\n",
            "TP = 112, TN = 1227,FP = 341, FN = 128\n",
            "EM Accuracy : 0.0684931506849315\n",
            "DS Accuracy : 0.7185408929835894\n",
            "Micro F1    : 0.29921813655533985\n",
            "Macro F1 Score = 0.32323232323232326\n",
            "***************************************************************\n",
            "predicting_ Epoch : 4\n",
            "Number of Test sentences : 73\n",
            "TP = 98, TN = 1221,FP = 347, FN = 142\n",
            "EM Accuracy : 0.0547945205479452\n",
            "DS Accuracy : 0.6701397370652837\n",
            "Micro F1    : 0.275757278355989\n",
            "Macro F1 Score = 0.28613138686131384\n",
            "***************************************************************\n",
            "predicting_ Epoch : 5\n",
            "Number of Test sentences : 73\n",
            "TP = 70, TN = 1227,FP = 341, FN = 170\n",
            "EM Accuracy : 0.0684931506849315\n",
            "DS Accuracy : 0.6513113867628323\n",
            "Micro F1    : 0.2066446491104026\n",
            "Macro F1 Score = 0.21505376344086022\n",
            "***************************************************************\n",
            "predicting_ Epoch : 6\n",
            "Number of Test sentences : 73\n",
            "TP = 64, TN = 1196,FP = 372, FN = 176\n",
            "EM Accuracy : 0.0410958904109589\n",
            "DS Accuracy : 0.6261141763141701\n",
            "Micro F1    : 0.1813340567571027\n",
            "Macro F1 Score = 0.1893491124260355\n",
            "***************************************************************\n",
            "predicting_ Epoch : 7\n",
            "Number of Test sentences : 73\n",
            "TP = 61, TN = 1216,FP = 352, FN = 179\n",
            "EM Accuracy : 0.0684931506849315\n",
            "DS Accuracy : 0.6342232305787339\n",
            "Micro F1    : 0.1806356504986642\n",
            "Macro F1 Score = 0.18683001531393567\n",
            "***************************************************************\n",
            "predicting_ Epoch : 8\n",
            "Number of Test sentences : 73\n",
            "TP = 57, TN = 1266,FP = 302, FN = 183\n",
            "EM Accuracy : 0.0684931506849315\n",
            "DS Accuracy : 0.6725750738075794\n",
            "Micro F1    : 0.18283147598216098\n",
            "Macro F1 Score = 0.19031719532554256\n",
            "***************************************************************\n",
            "predicting_ Epoch : 9\n",
            "Number of Test sentences : 73\n",
            "TP = 81, TN = 1292,FP = 276, FN = 159\n",
            "EM Accuracy : 0.0547945205479452\n",
            "DS Accuracy : 0.7077313549338313\n",
            "Micro F1    : 0.2619257454873894\n",
            "Macro F1 Score = 0.271356783919598\n",
            "***************************************************************\n",
            "predicting_ Epoch : 10\n",
            "Number of Test sentences : 73\n",
            "TP = 88, TN = 1295,FP = 273, FN = 152\n",
            "EM Accuracy : 0.0684931506849315\n",
            "DS Accuracy : 0.7101216281185925\n",
            "Micro F1    : 0.28026794362410806\n",
            "Macro F1 Score = 0.2928452579034942\n",
            "***************************************************************\n",
            "predicting_ Epoch : 11\n",
            "Number of Test sentences : 73\n",
            "TP = 89, TN = 1281,FP = 287, FN = 151\n",
            "EM Accuracy : 0.0684931506849315\n",
            "DS Accuracy : 0.6994409016819733\n",
            "Micro F1    : 0.27341322836890936\n",
            "Macro F1 Score = 0.288961038961039\n",
            "***************************************************************\n",
            "predicting_ Epoch : 12\n",
            "Number of Test sentences : 73\n",
            "TP = 88, TN = 1336,FP = 232, FN = 152\n",
            "EM Accuracy : 0.0547945205479452\n",
            "DS Accuracy : 0.7448284413213616\n",
            "Micro F1    : 0.3036610180042896\n",
            "Macro F1 Score = 0.3142857142857143\n",
            "***************************************************************\n",
            "predicting_ Epoch : 13\n",
            "Number of Test sentences : 73\n",
            "TP = 89, TN = 1337,FP = 231, FN = 151\n",
            "EM Accuracy : 0.0410958904109589\n",
            "DS Accuracy : 0.745859843138191\n",
            "Micro F1    : 0.30659684571852186\n",
            "Macro F1 Score = 0.31785714285714284\n",
            "***************************************************************\n",
            "predicting_ Epoch : 14\n",
            "Number of Test sentences : 73\n",
            "TP = 88, TN = 1339,FP = 229, FN = 152\n",
            "EM Accuracy : 0.0410958904109589\n",
            "DS Accuracy : 0.7441257969596664\n",
            "Micro F1    : 0.3056974407095278\n",
            "Macro F1 Score = 0.31597845601436264\n",
            "***************************************************************\n",
            "predicting_ Epoch : 15\n",
            "Number of Test sentences : 73\n",
            "TP = 87, TN = 1343,FP = 225, FN = 153\n",
            "EM Accuracy : 0.0547945205479452\n",
            "DS Accuracy : 0.7469974579482473\n",
            "Micro F1    : 0.3073276039029464\n",
            "Macro F1 Score = 0.31521739130434784\n",
            "***************************************************************\n",
            "predicting_ Epoch : 16\n",
            "Number of Test sentences : 73\n",
            "TP = 84, TN = 1386,FP = 182, FN = 156\n",
            "EM Accuracy : 0.1506849315068493\n",
            "DS Accuracy : 0.7866874841653767\n",
            "Micro F1    : 0.3317379728338633\n",
            "Macro F1 Score = 0.33201581027667987\n",
            "***************************************************************\n",
            "predicting_ Epoch : 17\n",
            "Number of Test sentences : 73\n",
            "TP = 89, TN = 1430,FP = 138, FN = 151\n",
            "EM Accuracy : 0.2465753424657534\n",
            "DS Accuracy : 0.821983313815222\n",
            "Micro F1    : 0.37894974127850845\n",
            "Macro F1 Score = 0.3811563169164882\n",
            "***************************************************************\n",
            "predicting_ Epoch : 18\n",
            "Number of Test sentences : 73\n",
            "TP = 88, TN = 1449,FP = 119, FN = 152\n",
            "EM Accuracy : 0.2328767123287671\n",
            "DS Accuracy : 0.8397391610902767\n",
            "Micro F1    : 0.39595860760244317\n",
            "Macro F1 Score = 0.39373601789709173\n",
            "***************************************************************\n",
            "predicting_ Epoch : 19\n",
            "Number of Test sentences : 73\n",
            "TP = 83, TN = 1457,FP = 111, FN = 157\n",
            "EM Accuracy : 0.2328767123287671\n",
            "DS Accuracy : 0.8415264755503561\n",
            "Micro F1    : 0.39232441835181564\n",
            "Macro F1 Score = 0.3824884792626728\n",
            "***************************************************************\n",
            "predicting_ Epoch : 20\n",
            "Number of Test sentences : 73\n",
            "TP = 82, TN = 1465,FP = 103, FN = 158\n",
            "EM Accuracy : 0.2465753424657534\n",
            "DS Accuracy : 0.8461516764796783\n",
            "Micro F1    : 0.39156338334420526\n",
            "Macro F1 Score = 0.38588235294117645\n",
            "***************************************************************\n",
            "predicting_ Epoch : 21\n",
            "Number of Test sentences : 73\n",
            "TP = 90, TN = 1465,FP = 103, FN = 150\n",
            "EM Accuracy : 0.2876712328767123\n",
            "DS Accuracy : 0.853821037259585\n",
            "Micro F1    : 0.423744292237443\n",
            "Macro F1 Score = 0.41570438799076215\n",
            "***************************************************************\n",
            "predicting_ Epoch : 22\n",
            "Number of Test sentences : 73\n",
            "TP = 91, TN = 1458,FP = 110, FN = 149\n",
            "EM Accuracy : 0.3287671232876712\n",
            "DS Accuracy : 0.8473582426302702\n",
            "Micro F1    : 0.41687619838304774\n",
            "Macro F1 Score = 0.4126984126984127\n",
            "***************************************************************\n",
            "predicting_ Epoch : 23\n",
            "Number of Test sentences : 73\n",
            "TP = 90, TN = 1463,FP = 105, FN = 150\n",
            "EM Accuracy : 0.273972602739726\n",
            "DS Accuracy : 0.8508275091051584\n",
            "Micro F1    : 0.4141214189159395\n",
            "Macro F1 Score = 0.41379310344827586\n",
            "***************************************************************\n",
            "predicting_ Epoch : 24\n",
            "Number of Test sentences : 73\n",
            "TP = 87, TN = 1467,FP = 101, FN = 153\n",
            "EM Accuracy : 0.2465753424657534\n",
            "DS Accuracy : 0.8553832778825075\n",
            "Micro F1    : 0.40436633381838866\n",
            "Macro F1 Score = 0.40654205607476634\n",
            "***************************************************************\n",
            "predicting_ Epoch : 25\n",
            "Number of Test sentences : 73\n",
            "TP = 92, TN = 1463,FP = 105, FN = 148\n",
            "EM Accuracy : 0.2876712328767123\n",
            "DS Accuracy : 0.852135698632526\n",
            "Micro F1    : 0.42084528865350795\n",
            "Macro F1 Score = 0.42105263157894735\n",
            "***************************************************************\n",
            "predicting_ Epoch : 26\n",
            "Number of Test sentences : 73\n",
            "TP = 89, TN = 1464,FP = 104, FN = 151\n",
            "EM Accuracy : 0.2602739726027397\n",
            "DS Accuracy : 0.8519285161521617\n",
            "Micro F1    : 0.4040757568154829\n",
            "Macro F1 Score = 0.4110854503464203\n",
            "***************************************************************\n",
            "predicting_ Epoch : 27\n",
            "Number of Test sentences : 73\n",
            "TP = 89, TN = 1469,FP = 99, FN = 151\n",
            "EM Accuracy : 0.2876712328767123\n",
            "DS Accuracy : 0.8580367950260817\n",
            "Micro F1    : 0.4222665462391491\n",
            "Macro F1 Score = 0.4158878504672897\n",
            "***************************************************************\n",
            "predicting_ Epoch : 28\n",
            "Number of Test sentences : 73\n",
            "TP = 88, TN = 1463,FP = 105, FN = 152\n",
            "EM Accuracy : 0.2465753424657534\n",
            "DS Accuracy : 0.8507270808250214\n",
            "Micro F1    : 0.40309933597604847\n",
            "Macro F1 Score = 0.4064665127020785\n",
            "***************************************************************\n",
            "predicting_ Epoch : 29\n",
            "Number of Test sentences : 73\n",
            "TP = 90, TN = 1455,FP = 113, FN = 150\n",
            "EM Accuracy : 0.273972602739726\n",
            "DS Accuracy : 0.843244610371263\n",
            "Micro F1    : 0.39500560322478134\n",
            "Macro F1 Score = 0.40632054176072235\n",
            "Saved model to disk\n",
            "Fold 3\n",
            "147 77\n",
            "150 74\n",
            "Starting Epochs\n",
            "***************************************************************\n",
            "predicting_ Epoch : 0\n",
            "Number of Test sentences : 74\n",
            "TP = 99, TN = 1205,FP = 650, FN = 166\n",
            "EM Accuracy : 0.04054054054054054\n",
            "DS Accuracy : 0.6090790731098844\n",
            "Micro F1    : 0.18043111556052452\n",
            "Macro F1 Score = 0.1952662721893491\n",
            "***************************************************************\n",
            "predicting_ Epoch : 1\n",
            "Number of Test sentences : 74\n",
            "TP = 90, TN = 1304,FP = 551, FN = 175\n",
            "EM Accuracy : 0.08108108108108109\n",
            "DS Accuracy : 0.6330836892596098\n",
            "Micro F1    : 0.17673137485931942\n",
            "Macro F1 Score = 0.1986754966887417\n",
            "***************************************************************\n",
            "predicting_ Epoch : 2\n",
            "Number of Test sentences : 74\n",
            "TP = 115, TN = 1286,FP = 569, FN = 150\n",
            "EM Accuracy : 0.013513513513513514\n",
            "DS Accuracy : 0.5770398606763256\n",
            "Micro F1    : 0.22007996556758164\n",
            "Macro F1 Score = 0.24236037934668073\n",
            "***************************************************************\n",
            "predicting_ Epoch : 3\n",
            "Number of Test sentences : 74\n",
            "TP = 125, TN = 1316,FP = 539, FN = 140\n",
            "EM Accuracy : 0.06756756756756757\n",
            "DS Accuracy : 0.5941348882952596\n",
            "Micro F1    : 0.24231799645886332\n",
            "Macro F1 Score = 0.2691065662002153\n",
            "***************************************************************\n",
            "predicting_ Epoch : 4\n",
            "Number of Test sentences : 74\n",
            "TP = 126, TN = 1372,FP = 483, FN = 139\n",
            "EM Accuracy : 0.08108108108108109\n",
            "DS Accuracy : 0.6228524930513833\n",
            "Micro F1    : 0.2586946042828396\n",
            "Macro F1 Score = 0.28832951945080093\n",
            "***************************************************************\n",
            "predicting_ Epoch : 5\n",
            "Number of Test sentences : 74\n",
            "TP = 120, TN = 1397,FP = 458, FN = 145\n",
            "EM Accuracy : 0.08108108108108109\n",
            "DS Accuracy : 0.6277861072523043\n",
            "Micro F1    : 0.2527634781790792\n",
            "Macro F1 Score = 0.2846975088967972\n",
            "***************************************************************\n",
            "predicting_ Epoch : 6\n",
            "Number of Test sentences : 74\n",
            "TP = 133, TN = 1363,FP = 492, FN = 132\n",
            "EM Accuracy : 0.05405405405405406\n",
            "DS Accuracy : 0.6281229853664617\n",
            "Micro F1    : 0.27959389339599\n",
            "Macro F1 Score = 0.298876404494382\n",
            "***************************************************************\n",
            "predicting_ Epoch : 7\n",
            "Number of Test sentences : 74\n",
            "TP = 125, TN = 1336,FP = 519, FN = 140\n",
            "EM Accuracy : 0.05405405405405406\n",
            "DS Accuracy : 0.6131138377940719\n",
            "Micro F1    : 0.2652873933041692\n",
            "Macro F1 Score = 0.27502750275027504\n",
            "***************************************************************\n",
            "predicting_ Epoch : 8\n",
            "Number of Test sentences : 74\n",
            "TP = 109, TN = 1387,FP = 468, FN = 156\n",
            "EM Accuracy : 0.02702702702702703\n",
            "DS Accuracy : 0.6258003893193763\n",
            "Micro F1    : 0.24595474419756908\n",
            "Macro F1 Score = 0.2589073634204275\n",
            "***************************************************************\n",
            "predicting_ Epoch : 9\n",
            "Number of Test sentences : 74\n",
            "TP = 113, TN = 1400,FP = 455, FN = 152\n",
            "EM Accuracy : 0.04054054054054054\n",
            "DS Accuracy : 0.6323800095083908\n",
            "Micro F1    : 0.25493645957134803\n",
            "Macro F1 Score = 0.27130852340936373\n",
            "***************************************************************\n",
            "predicting_ Epoch : 10\n",
            "Number of Test sentences : 74\n",
            "TP = 117, TN = 1525,FP = 330, FN = 148\n",
            "EM Accuracy : 0.06756756756756757\n",
            "DS Accuracy : 0.7215829126660129\n",
            "Micro F1    : 0.33064230161004354\n",
            "Macro F1 Score = 0.32865168539325845\n",
            "***************************************************************\n",
            "predicting_ Epoch : 11\n",
            "Number of Test sentences : 74\n",
            "TP = 117, TN = 1526,FP = 329, FN = 148\n",
            "EM Accuracy : 0.13513513513513514\n",
            "DS Accuracy : 0.7188131405565559\n",
            "Micro F1    : 0.32890663451008273\n",
            "Macro F1 Score = 0.3291139240506329\n",
            "***************************************************************\n",
            "predicting_ Epoch : 12\n",
            "Number of Test sentences : 74\n",
            "TP = 111, TN = 1580,FP = 275, FN = 154\n",
            "EM Accuracy : 0.13513513513513514\n",
            "DS Accuracy : 0.7515078956693124\n",
            "Micro F1    : 0.3493083045714625\n",
            "Macro F1 Score = 0.34101382488479265\n",
            "***************************************************************\n",
            "predicting_ Epoch : 13\n",
            "Number of Test sentences : 74\n",
            "TP = 109, TN = 1625,FP = 230, FN = 156\n",
            "EM Accuracy : 0.14864864864864866\n",
            "DS Accuracy : 0.7880092131301457\n",
            "Micro F1    : 0.3685787536871128\n",
            "Macro F1 Score = 0.3609271523178808\n",
            "***************************************************************\n",
            "predicting_ Epoch : 14\n",
            "Number of Test sentences : 74\n",
            "TP = 110, TN = 1638,FP = 217, FN = 155\n",
            "EM Accuracy : 0.14864864864864866\n",
            "DS Accuracy : 0.7954519919008725\n",
            "Micro F1    : 0.37903070256011434\n",
            "Macro F1 Score = 0.3716216216216216\n",
            "***************************************************************\n",
            "predicting_ Epoch : 15\n",
            "Number of Test sentences : 74\n",
            "TP = 110, TN = 1658,FP = 197, FN = 155\n",
            "EM Accuracy : 0.13513513513513514\n",
            "DS Accuracy : 0.8041824888850179\n",
            "Micro F1    : 0.38754260004260005\n",
            "Macro F1 Score = 0.38461538461538464\n",
            "***************************************************************\n",
            "predicting_ Epoch : 16\n",
            "Number of Test sentences : 74\n",
            "TP = 106, TN = 1676,FP = 179, FN = 159\n",
            "EM Accuracy : 0.17567567567567569\n",
            "DS Accuracy : 0.8188878867929709\n",
            "Micro F1    : 0.3799098622628033\n",
            "Macro F1 Score = 0.38545454545454544\n",
            "***************************************************************\n",
            "predicting_ Epoch : 17\n",
            "Number of Test sentences : 74\n",
            "TP = 112, TN = 1673,FP = 182, FN = 153\n",
            "EM Accuracy : 0.16216216216216217\n",
            "DS Accuracy : 0.8224417988623667\n",
            "Micro F1    : 0.40737153457741687\n",
            "Macro F1 Score = 0.4007155635062612\n",
            "***************************************************************\n",
            "predicting_ Epoch : 18\n",
            "Number of Test sentences : 74\n",
            "TP = 104, TN = 1689,FP = 166, FN = 161\n",
            "EM Accuracy : 0.16216216216216217\n",
            "DS Accuracy : 0.8280050773743316\n",
            "Micro F1    : 0.3891692014272659\n",
            "Macro F1 Score = 0.38878504672897196\n",
            "***************************************************************\n",
            "predicting_ Epoch : 19\n",
            "Number of Test sentences : 74\n",
            "TP = 112, TN = 1689,FP = 166, FN = 153\n",
            "EM Accuracy : 0.16216216216216217\n",
            "DS Accuracy : 0.8376015210959628\n",
            "Micro F1    : 0.4086351358410182\n",
            "Macro F1 Score = 0.4125230202578269\n",
            "***************************************************************\n",
            "predicting_ Epoch : 20\n",
            "Number of Test sentences : 74\n",
            "TP = 110, TN = 1676,FP = 179, FN = 155\n",
            "EM Accuracy : 0.16216216216216217\n",
            "DS Accuracy : 0.8297859020096907\n",
            "Micro F1    : 0.4083623980682804\n",
            "Macro F1 Score = 0.3971119133574007\n",
            "***************************************************************\n",
            "predicting_ Epoch : 21\n",
            "Number of Test sentences : 74\n",
            "TP = 104, TN = 1696,FP = 159, FN = 161\n",
            "EM Accuracy : 0.17567567567567569\n",
            "DS Accuracy : 0.8382156361619743\n",
            "Micro F1    : 0.4038697908263125\n",
            "Macro F1 Score = 0.3939393939393939\n",
            "***************************************************************\n",
            "predicting_ Epoch : 22\n",
            "Number of Test sentences : 74\n",
            "TP = 113, TN = 1678,FP = 177, FN = 152\n",
            "EM Accuracy : 0.13513513513513514\n",
            "DS Accuracy : 0.8331343656018074\n",
            "Micro F1    : 0.41448941545715745\n",
            "Macro F1 Score = 0.4072072072072072\n",
            "***************************************************************\n",
            "predicting_ Epoch : 23\n",
            "Number of Test sentences : 74\n",
            "TP = 109, TN = 1690,FP = 165, FN = 156\n",
            "EM Accuracy : 0.22972972972972974\n",
            "DS Accuracy : 0.8425350450328202\n",
            "Micro F1    : 0.4107105588841831\n",
            "Macro F1 Score = 0.4044526901669759\n",
            "***************************************************************\n",
            "predicting_ Epoch : 24\n",
            "Number of Test sentences : 74\n",
            "TP = 108, TN = 1681,FP = 174, FN = 157\n",
            "EM Accuracy : 0.20270270270270271\n",
            "DS Accuracy : 0.8385338586023934\n",
            "Micro F1    : 0.416604551068498\n",
            "Macro F1 Score = 0.39488117001828155\n",
            "***************************************************************\n",
            "predicting_ Epoch : 25\n",
            "Number of Test sentences : 74\n",
            "TP = 107, TN = 1685,FP = 170, FN = 158\n",
            "EM Accuracy : 0.24324324324324326\n",
            "DS Accuracy : 0.8358248925563669\n",
            "Micro F1    : 0.41303271803271807\n",
            "Macro F1 Score = 0.3948339483394834\n",
            "***************************************************************\n",
            "predicting_ Epoch : 26\n",
            "Number of Test sentences : 74\n",
            "TP = 106, TN = 1679,FP = 176, FN = 159\n",
            "EM Accuracy : 0.20270270270270271\n",
            "DS Accuracy : 0.8392653158944435\n",
            "Micro F1    : 0.4076563098621922\n",
            "Macro F1 Score = 0.3875685557586837\n",
            "***************************************************************\n",
            "predicting_ Epoch : 27\n",
            "Number of Test sentences : 74\n",
            "TP = 104, TN = 1704,FP = 151, FN = 161\n",
            "EM Accuracy : 0.24324324324324326\n",
            "DS Accuracy : 0.8475391229927449\n",
            "Micro F1    : 0.41207231207231204\n",
            "Macro F1 Score = 0.4\n",
            "***************************************************************\n",
            "predicting_ Epoch : 28\n",
            "Number of Test sentences : 74\n",
            "TP = 104, TN = 1701,FP = 154, FN = 161\n",
            "EM Accuracy : 0.20270270270270271\n",
            "DS Accuracy : 0.8463520849636016\n",
            "Micro F1    : 0.4046778916344133\n",
            "Macro F1 Score = 0.3977055449330784\n",
            "***************************************************************\n",
            "predicting_ Epoch : 29\n",
            "Number of Test sentences : 74\n",
            "TP = 108, TN = 1683,FP = 172, FN = 157\n",
            "EM Accuracy : 0.1891891891891892\n",
            "DS Accuracy : 0.8418842120059776\n",
            "Micro F1    : 0.417442494648377\n",
            "Macro F1 Score = 0.3963302752293578\n",
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}