{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SMDM_CodeBase_IMPROVEMENT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5DA7c0VKSYX"
      },
      "source": [
        "**Sarcasm Target Detection Codebase**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "f_dmEBsSBf8M",
        "outputId": "9fa52cde-842d-49e8-fc27-78779409c537"
      },
      "source": [
        "# Upload 'snippets.xlsx' from the local file system.\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b2166f99-198a-4ddc-86c9-f93160669027\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b2166f99-198a-4ddc-86c9-f93160669027\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving snippetshindi.xlsx to snippetshindi.xlsx\n",
            "User uploaded file \"snippetshindi.xlsx\" with length 41575 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lu-Fvr38C2Ho",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be1b5415-0e58-4fc4-dae7-eb56183e213e"
      },
      "source": [
        "# Mount google drive to use 'crawl-300d-2M.vec'. \n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LweGufCtKzba"
      },
      "source": [
        "# Import basic maths and processing libraries.\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from keras.layers import Dense ,LSTM,concatenate,Input,Flatten\n",
        "from keras.models import Model\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "import pickle\n",
        "import codecs\n",
        "from collections import deque"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2npgiN0QQNS"
      },
      "source": [
        "# Excel file contains no header column and names gives custom column names\n",
        "df = pd.read_excel(\"snippetshindi.xlsx\", sheet_name=None, header=None, names=['Snippet','target'])\n",
        "df = df['Sheet1']\n",
        "embedding_file = '/gdrive/MyDrive/gloveHindi.txt'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggbf5YYgjyQI"
      },
      "source": [
        "# Removes all non-alpha numeric characters except ',' from a given strring\n",
        "def clearLine(line):\n",
        "  cleanedLine = ''\n",
        "  for letter in line:\n",
        "    if letter == '?' or letter == '!' or letter == ',' or letter == '\"' or letter == '-' or letter == ';' or letter == '.' :\n",
        "      cleanedLine += ' '\n",
        "    else:\n",
        "      cleanedLine += letter\n",
        "  return cleanedLine"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQlSp4C5TtL1"
      },
      "source": [
        "# Load pre-trained fasttext word embedding from the file\n",
        "def loadEmbed():\n",
        "    print('loading word embeddings...')\n",
        "    embeddings_index = {}\n",
        "    f = codecs.open(embedding_file, encoding='utf-8')\n",
        "    for line in f:\n",
        "        # Line has the format : Word val1 val2 val3 ..... val300\n",
        "        values = line.rstrip().rsplit(' ')\n",
        "        word = values[0]\n",
        "        coefs = np.asarray(values[-100:], dtype='float32')\n",
        "        embeddings_index[word] = coefs\n",
        "    f.close()\n",
        "    print('found %s word vectors' % len(embeddings_index))\n",
        "    return embeddings_index"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cv6yMkNMgP9u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9eca0f69-b78d-46dc-d2c6-936c84f3835d"
      },
      "source": [
        "# Loading pre-trained embeddings\n",
        "model=loadEmbed()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading word embeddings...\n",
            "found 336023 word vectors\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPext8rQigyp"
      },
      "source": [
        "# Stores all distinct words in the dataset.\n",
        "all_words=[]\n",
        "\n",
        "# Extract all poosible words in the dataset\n",
        "for i in range(len(df['Snippet'])):\n",
        "    line = clearLine(df['Snippet'][i])\n",
        "    all_words.extend(line.split())\n",
        "\n",
        "# get all unique words from the dataset\n",
        "all_words=list(dict.fromkeys(all_words))\n",
        "all_words=[x.lower() for x in all_words]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yC4I9QzPiomu"
      },
      "source": [
        "# Stores the vector representations of the words from the dataset.\n",
        "embeddings={}\n",
        "for each in all_words:\n",
        "    # Get vectors for words in the dataset\n",
        "    if each not in model.keys(): \n",
        "        embeddings[each]=[1]*100\n",
        "    else:\n",
        "        embeddings[each]=model[each]\n",
        "\n",
        "# make <pad> as the 0-vector\n",
        "embeddings['<pad>'] = [0]*100\n",
        "# make <start> token to start vector\n",
        "embeddings['<start>'] = [1] + [0]*99\n",
        "# make <end> token to end vector \n",
        "embeddings['<end>'] = [0]*99 + [1]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FzhEcqOI0Cq"
      },
      "source": [
        "# Prepare the left context, right context, and candidate word from the dataset.\n",
        "# The pre-processed data has the data type string\n",
        "# Pre-Processed Data (ppd)\n",
        "\n",
        "ppd = {}\n",
        "ppd['left_context'] = []\n",
        "ppd['right_context'] = []\n",
        "ppd['Candidate_word'] = []\n",
        "ppd['target_status'] = []\n",
        "\n",
        "for i in range(len(df['Snippet'])):\n",
        "  # clean the line and split the line into individual words\n",
        "  line = clearLine(df['Snippet'][i].lower());\n",
        "  line = line.split()\n",
        "  # get each individual word in sarcasm target to identify possible sarcasm\n",
        "  # target words in the sentence\n",
        "  targetList = df['target'][i].lower().split(\",\")\n",
        "  targetWord = []\n",
        "  for tl in targetList:\n",
        "    targetWord.extend(tl.split())\n",
        "  \n",
        "  # Choosing each word in the sentence as candidate word, extract the left context,\n",
        "  # right context and the target label.\n",
        "  for i in range(len(line)):\n",
        "    word = line[i]\n",
        "    ppd['Candidate_word'].append(word)\n",
        "    ppd['left_context'].append([\"<start>\"] + line[:i])\n",
        "    ppd['right_context'].append(line[i+1:] + [\"<end>\"])\n",
        "    ppd['target_status'].append(int(word in targetWord))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ov65vnKME1Wv"
      },
      "source": [
        "# Embedding Left Context\n",
        "# Convert each word in left context into vector representation to be used as input \n",
        "keras_left_context = []\n",
        "for i in range(len(ppd['left_context'])):\n",
        "    one_vector = []\n",
        "    temp = ppd['left_context'][i]\n",
        "    for m in temp:\n",
        "        one_vector.append(embeddings[m])\n",
        "    one_vector.extend([embeddings['<pad>'] for x in range(100 - len(ppd['left_context'][i]))])\n",
        "    keras_left_context.append(one_vector)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjUxOeBUH49B"
      },
      "source": [
        "# Embedding Right Context \n",
        "# Convert each word in right context into vector representation to be used as input \n",
        "keras_right_context = []\n",
        "for i in range(len(ppd['right_context'])):\n",
        "    one_vector = []\n",
        "    temp = ppd['right_context'][i]\n",
        "    for m in temp:\n",
        "        one_vector.append(embeddings[m])\n",
        "    one_vector.extend([embeddings['<pad>'] for x in range(100 - len(ppd['right_context'][i]))])\n",
        "    keras_right_context.append(one_vector)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5ehP344Ic1y"
      },
      "source": [
        "# Embedding Candidate Word\n",
        "# Convert each candidate word into vector representation to be used as input \n",
        "keras_middle = []\n",
        "for i in range(len(ppd['Candidate_word'])):\n",
        "    keras_middle.append(embeddings[ppd['Candidate_word'][i]])\n",
        "\n",
        "labels = ppd['target_status']"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28iw-AYwJCHr"
      },
      "source": [
        "Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iN1wcrRWKt8E"
      },
      "source": [
        "# Function to group together candidate-words belonging to the same line.\n",
        "def compress():\n",
        "    lengths = []\n",
        "    for i in range (1,len(ppd['left_context'])):\n",
        "        # If left context contains only '<start>'\n",
        "        if len(ppd['left_context'][i]) == 1:\n",
        "            lengths.append(i)\n",
        "    lengths.append(len(ppd['left_context']))\n",
        "    compressor = []\n",
        "    compressor.append(range(lengths[0]))\n",
        "    for i in range (1,len(lengths)):\n",
        "        compressor.append(range(lengths[i-1],lengths[i]))\n",
        "    return compressor"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNWYsrPpP0es"
      },
      "source": [
        "comp = compress()"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUUEUouCNQmb"
      },
      "source": [
        "# Training Data, Test Data Preparation\n",
        "\n",
        "def prep (train_indices, test_indices):\n",
        "    print (len(train_indices), len(test_indices))\n",
        "\n",
        "    # Ungroup training dataset candidate-words belonging to the same line.\n",
        "    train_ids = []\n",
        "    for i in range(len(train_indices)):\n",
        "        train_ids.extend(comp[train_indices[i]])\n",
        "\n",
        "    # Ungroup testing dataset candidate-words belonging to the same line.\n",
        "    test_ids = []\n",
        "    for i in range(len(test_indices)):\n",
        "        test_ids.extend(comp[test_indices[i]])\n",
        "\n",
        "    # Training Data Preparation\n",
        "    train_left   = []\n",
        "    train_right  = []\n",
        "    train_middle = []\n",
        "    train_labels = []\n",
        "\n",
        "    for id in train_ids:\n",
        "        train_left.append(keras_left_context[id])\n",
        "        train_right.append(keras_right_context[id])\n",
        "        train_middle.append(keras_middle[id])\n",
        "        train_labels.append(labels[id])\n",
        "\n",
        "    train_left   = np.array(train_left)\n",
        "    train_right  = np.array(train_right)\n",
        "    train_middle = np.array(train_middle)\n",
        "    train_labels = np.array(train_labels)\n",
        "    train_middle = np.expand_dims(train_middle,axis=1)\n",
        "\n",
        "    # Testing Data Preparation\n",
        "    val_left   = []\n",
        "    val_right  = []\n",
        "    val_middle = []\n",
        "    val_labels = []\n",
        "\n",
        "    for id in test_ids:\n",
        "        val_left.append(keras_left_context[id])\n",
        "        val_right.append(keras_right_context[id])\n",
        "        val_middle.append(keras_middle[id])\n",
        "        val_labels.append(labels[id])\n",
        "\n",
        "    val_left   = np.array(val_left)\n",
        "    val_right  = np.array(val_right)\n",
        "    val_middle = np.array(val_middle)\n",
        "    val_labels = np.array(val_labels)\n",
        "    val_middle = np.expand_dims(val_middle, axis=1)\n",
        "\n",
        "    # Below part only for TD lstm\n",
        "    if mode == 'TD':\t    \n",
        "      train_left = np.concatenate((train_left, train_middle), axis=1)\n",
        "      train_right = np.concatenate((train_middle, train_right), axis=1)\n",
        "      val_left = np.concatenate((val_left, val_middle), axis=1)\n",
        "      val_right = np.concatenate((val_middle, val_right), axis=1)\n",
        "\n",
        "    return(train_left,train_right,train_middle,train_labels,val_left,val_right,val_middle,val_labels)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34X2_lDDA-FB"
      },
      "source": [
        "def de_comp(arr, test_indices):\n",
        "    arr = deque(arr)\n",
        "    fin = []\n",
        "    for i in test_indices:\n",
        "        temp = []\n",
        "        for j in range(len(comp[i])):\n",
        "            temp.append(arr.popleft())\n",
        "        fin.append(temp)\n",
        "    return (fin)    "
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYk7ipoiBF43"
      },
      "source": [
        "def accuracy (pred, labels, test_indices):\n",
        "    pred = pred[0]\n",
        "    num_sent = len(comp)\n",
        "    num_words = len(pred)\n",
        "    threshold = 0\n",
        "    cnt = 0\n",
        "    # Threshold calculation for binary classification problem\n",
        "    for a,b in zip (pred,labels):\n",
        "        if b==1.0:\n",
        "            threshold+=a\n",
        "            cnt+=1\n",
        "    threshold = threshold.item()/cnt\n",
        "\n",
        "    pred_th = []\n",
        "    for x in pred:\n",
        "        if (x<=threshold):\n",
        "            pred_th.append(0)\n",
        "        else :\n",
        "            pred_th.append(1)\n",
        "\n",
        "    pred_th = np.array(pred_th)\n",
        "    print (\"Number of Test sentences : {}\".format(len(test_indices)))\n",
        "    error = pred_th-labels\n",
        "    error_d  = de_comp(error,test_indices)\n",
        "    labels_d = de_comp(labels,test_indices)\n",
        "    pred_d   = de_comp(pred_th,test_indices)\n",
        "    em_cnt = 0\n",
        "    ds_cnt = 0\n",
        "    mic_f1 = 0\n",
        "\n",
        "    for err in error_d:\n",
        "        if (sum(err)==0):\n",
        "           em_cnt += 1\n",
        "        ds_cnt += float(len(err)-sum(np.abs(err)))/len(err)\n",
        "\n",
        "    for lab, pre in zip(labels_d,pred_d):\n",
        "\n",
        "        tp = 0\n",
        "        fp = 0\n",
        "        fn = 0\n",
        "        tn = 0\n",
        "              \n",
        "        for i,j in zip(lab,pre):\n",
        "            if (int(i) == 1)  and (int(j) ==0) :\n",
        "                fn += 1\n",
        "            elif (int(i) == 0)  and (int(j) ==1) :\n",
        "                fp += 1\n",
        "            elif (int(i) == 0)  and (int(j) ==0) :\n",
        "                tn += 1\n",
        "            elif (int(i) == 1) and (int(j) ==1):\n",
        "                tp += 1\n",
        "        try : \n",
        "            mic_f1 += float(2*tp) / (2*tp + fn +fp)\n",
        "        except :\n",
        "            pass\n",
        "\n",
        "    TP=0\n",
        "    TN=0\n",
        "    FP=0\n",
        "    FN=0\n",
        "    for a,b in zip(labels, pred_th):\n",
        "\n",
        "        if int(a)==0 and b==0:\n",
        "            TN+=1\n",
        "        if int(a)==1 and b==1:\n",
        "            TP+=1\n",
        "        if int(a)==0 and b==1:\n",
        "            FP+=1\n",
        "        if int(a)==1 and b==0:\n",
        "            FN+=1 \n",
        "    print (\"TP = {}, TN = {},FP = {}, FN = {}\".format(TP,TN,FP,FN))\n",
        "    F1 = float(2*TP)/(2*TP + FP+ FN)\n",
        "    EM = float(em_cnt)/len(test_indices)\n",
        "    DS = float(ds_cnt)/len(test_indices)\n",
        "    uF1= float(mic_f1)/len(test_indices)\n",
        "    print (\"EM Accuracy : {}\".format(EM))\n",
        "    print (\"DS Accuracy : {}\".format(DS))\n",
        "    print (\"Micro F1    : {}\".format(uF1))\n",
        "    print (\"Macro F1 Score = {}\".format(F1))\n",
        "    return (pred_d, labels_d)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWC-tUwcAJx3"
      },
      "source": [
        "# Tuned-Hyper Parameters\n",
        "hidden_size = 32\n",
        "num_epochs=30\n",
        "layer_size = 16\n",
        "batch_size = 64\n",
        "\n",
        "# 'Uni' : Unidirectional LSTM  |  'Bi' : Bidirectional LSTM  | 'TD' : Target-dependent LSTM\n",
        "mode = 'Uni' "
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZkaHjZN1IPM"
      },
      "source": [
        "# Define the model and run the model for given epochs\n",
        "def model(train_l,train_r,train_m,train_labels,test_l,test_r,test_m,test_labels,test_indices):\n",
        "    # Create placeholder for each input type to define the model\n",
        "    x=Input(shape=(100, 100))\n",
        "    y=Input(shape=(100, 100))\n",
        "    z=Input(shape=(1, 100))\n",
        "\n",
        "    if mode == 'Bi':\n",
        "      # Define birectional layer on LSTM and use concat as the merge mode.\n",
        "    \tleft_out=Bidirectional(LSTM(hidden_size//2,return_sequences=False),input_shape=(train_l.shape[1:]))(x)      \n",
        "    \tmiddle = Bidirectional(LSTM(hidden_size//2,return_sequences=False),input_shape=(train_m.shape[1:]))(z)\n",
        "    \tright_out=Bidirectional(LSTM(hidden_size//2,return_sequences=False),input_shape=(train_r.shape[1:]))(y)\n",
        "\n",
        "    else:\n",
        "      # Define LSTM units\n",
        "    \tleft_out  = LSTM(hidden_size,return_sequences=False)(x)\n",
        "    \tmiddle    = LSTM(hidden_size,return_sequences=False)(z)\n",
        "    \tright_out = LSTM(hidden_size,return_sequences=False)(y)\n",
        "\n",
        "    if mode == 'TD':\n",
        "      out=concatenate([left_out,right_out],axis=-1)\n",
        "\n",
        "    if mode != 'TD':\n",
        "      out=concatenate([left_out,middle,right_out],axis=-1)\n",
        "\n",
        "    out=Dense(layer_size, activation='relu')(out)\n",
        "    output=Dense(1, activation='sigmoid')(out)\n",
        "    model = Model(inputs=[x,y,z], outputs=output)\n",
        "    model.compile(optimizer=Adam(lr=10e-5),loss='binary_crossentropy',metrics=['accuracy'])\n",
        "    print (\"Starting Epochs\")\n",
        "    for i in range(num_epochs):\n",
        "        model.fit([train_l,train_r,train_m],train_labels,batch_size=batch_size, epochs=1,verbose=0)\n",
        "        print('***************************************************************')\n",
        "        print (\"predicting_ Epoch : {}\".format(i))\n",
        "        pred_val=[]\n",
        "        pred_val.append(model.predict([test_l,test_r,test_m]))\n",
        "        pre_d, lab_d = accuracy (pred_val, test_labels,test_indices)\n",
        "    return model"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFHCUy5jLV2e"
      },
      "source": [
        "# Dataset division for 3-fold cross validation\n",
        "indices = list(range(len(comp)))\n",
        "np.random.shuffle(indices)\n",
        "bins = []\n",
        "bins.append(indices[:int(0.33*len(indices))])\n",
        "bins.append(indices[int(0.33*len(indices)):int(0.66*len(indices))])\n",
        "bins.append(indices[int(0.66*len(indices)):])"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6hjPEsuN-33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23a4a142-6df7-4eca-8d3c-26af2de012ce"
      },
      "source": [
        "for i in range (3):\n",
        "    print (\"Fold {}\".format(i+1))\n",
        "    print (len(bins[0] + bins[1]),len(bins[2]))\n",
        "    train_left,train_right,train_middle,train_labels,val_left,val_right,val_middle,val_labels = prep (bins[i%3] + bins[(i+1)%3], bins[(i+2)%3])\n",
        "    Sar_model=model(train_left,train_right,train_middle,train_labels,val_left,val_right,val_middle,val_labels,bins[(i+2)%3])\n",
        "    Sar_model.save_weights(\"Bert Tweets Aug.h5\")\n",
        "    print(\"Saved model to disk\")"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold 1\n",
            "147 77\n",
            "147 77\n",
            "Starting Epochs\n",
            "***************************************************************\n",
            "predicting_ Epoch : 0\n",
            "Number of Test sentences : 77\n",
            "TP = 95, TN = 1170,FP = 1094, FN = 65\n",
            "EM Accuracy : 0.06493506493506493\n",
            "DS Accuracy : 0.5451067649481633\n",
            "Micro F1    : 0.15379407817784077\n",
            "Macro F1 Score = 0.14084507042253522\n",
            "***************************************************************\n",
            "predicting_ Epoch : 1\n",
            "Number of Test sentences : 77\n",
            "TP = 92, TN = 1244,FP = 1020, FN = 68\n",
            "EM Accuracy : 0.025974025974025976\n",
            "DS Accuracy : 0.5409092650766281\n",
            "Micro F1    : 0.14820563049824637\n",
            "Macro F1 Score = 0.14465408805031446\n",
            "***************************************************************\n",
            "predicting_ Epoch : 2\n",
            "Number of Test sentences : 77\n",
            "TP = 98, TN = 1203,FP = 1061, FN = 62\n",
            "EM Accuracy : 0.06493506493506493\n",
            "DS Accuracy : 0.48766412319655633\n",
            "Micro F1    : 0.14128377230758607\n",
            "Macro F1 Score = 0.14859742228961334\n",
            "***************************************************************\n",
            "predicting_ Epoch : 3\n",
            "Number of Test sentences : 77\n",
            "TP = 98, TN = 1178,FP = 1086, FN = 62\n",
            "EM Accuracy : 0.06493506493506493\n",
            "DS Accuracy : 0.4907544511050374\n",
            "Micro F1    : 0.14149755199351896\n",
            "Macro F1 Score = 0.14583333333333334\n",
            "***************************************************************\n",
            "predicting_ Epoch : 4\n",
            "Number of Test sentences : 77\n",
            "TP = 91, TN = 1143,FP = 1121, FN = 69\n",
            "EM Accuracy : 0.05194805194805195\n",
            "DS Accuracy : 0.4784683164028065\n",
            "Micro F1    : 0.12327288664248609\n",
            "Macro F1 Score = 0.1326530612244898\n",
            "***************************************************************\n",
            "predicting_ Epoch : 5\n",
            "Number of Test sentences : 77\n",
            "TP = 92, TN = 1084,FP = 1180, FN = 68\n",
            "EM Accuracy : 0.012987012987012988\n",
            "DS Accuracy : 0.4620873815621761\n",
            "Micro F1    : 0.11283713697933243\n",
            "Macro F1 Score = 0.12849162011173185\n",
            "***************************************************************\n",
            "predicting_ Epoch : 6\n",
            "Number of Test sentences : 77\n",
            "TP = 94, TN = 1105,FP = 1159, FN = 66\n",
            "EM Accuracy : 0.0\n",
            "DS Accuracy : 0.4675014025332643\n",
            "Micro F1    : 0.11662073035190722\n",
            "Macro F1 Score = 0.13305024769992924\n",
            "***************************************************************\n",
            "predicting_ Epoch : 7\n",
            "Number of Test sentences : 77\n",
            "TP = 77, TN = 1435,FP = 829, FN = 83\n",
            "EM Accuracy : 0.07792207792207792\n",
            "DS Accuracy : 0.6139203242152133\n",
            "Micro F1    : 0.10192277249008425\n",
            "Macro F1 Score = 0.14446529080675422\n",
            "***************************************************************\n",
            "predicting_ Epoch : 8\n",
            "Number of Test sentences : 77\n",
            "TP = 83, TN = 1319,FP = 945, FN = 77\n",
            "EM Accuracy : 0.07792207792207792\n",
            "DS Accuracy : 0.5657885209907174\n",
            "Micro F1    : 0.10748607123527189\n",
            "Macro F1 Score = 0.13973063973063973\n",
            "***************************************************************\n",
            "predicting_ Epoch : 9\n",
            "Number of Test sentences : 77\n",
            "TP = 60, TN = 1607,FP = 657, FN = 100\n",
            "EM Accuracy : 0.1038961038961039\n",
            "DS Accuracy : 0.6892317319611073\n",
            "Micro F1    : 0.08984567381595225\n",
            "Macro F1 Score = 0.13683010262257697\n",
            "***************************************************************\n",
            "predicting_ Epoch : 10\n",
            "Number of Test sentences : 77\n",
            "TP = 58, TN = 1653,FP = 611, FN = 102\n",
            "EM Accuracy : 0.14285714285714285\n",
            "DS Accuracy : 0.7129622963895607\n",
            "Micro F1    : 0.07657524825555075\n",
            "Macro F1 Score = 0.1399276236429433\n",
            "***************************************************************\n",
            "predicting_ Epoch : 11\n",
            "Number of Test sentences : 77\n",
            "TP = 57, TN = 1677,FP = 587, FN = 103\n",
            "EM Accuracy : 0.15584415584415584\n",
            "DS Accuracy : 0.7239198145713117\n",
            "Micro F1    : 0.07349896678896951\n",
            "Macro F1 Score = 0.1417910447761194\n",
            "***************************************************************\n",
            "predicting_ Epoch : 12\n",
            "Number of Test sentences : 77\n",
            "TP = 60, TN = 1578,FP = 686, FN = 100\n",
            "EM Accuracy : 0.15584415584415584\n",
            "DS Accuracy : 0.6743380534892522\n",
            "Micro F1    : 0.06781352672811732\n",
            "Macro F1 Score = 0.13245033112582782\n",
            "***************************************************************\n",
            "predicting_ Epoch : 13\n",
            "Number of Test sentences : 77\n",
            "TP = 51, TN = 1736,FP = 528, FN = 109\n",
            "EM Accuracy : 0.1038961038961039\n",
            "DS Accuracy : 0.7525093300781366\n",
            "Micro F1    : 0.07579936304778906\n",
            "Macro F1 Score = 0.13802435723951287\n",
            "***************************************************************\n",
            "predicting_ Epoch : 14\n",
            "Number of Test sentences : 77\n",
            "TP = 52, TN = 1733,FP = 531, FN = 108\n",
            "EM Accuracy : 0.11688311688311688\n",
            "DS Accuracy : 0.74762603015691\n",
            "Micro F1    : 0.07830178726166481\n",
            "Macro F1 Score = 0.13997308209959622\n",
            "***************************************************************\n",
            "predicting_ Epoch : 15\n",
            "Number of Test sentences : 77\n",
            "TP = 38, TN = 1837,FP = 427, FN = 122\n",
            "EM Accuracy : 0.11688311688311688\n",
            "DS Accuracy : 0.7791724917548195\n",
            "Micro F1    : 0.05086373668250995\n",
            "Macro F1 Score = 0.1216\n",
            "***************************************************************\n",
            "predicting_ Epoch : 16\n",
            "Number of Test sentences : 77\n",
            "TP = 47, TN = 1779,FP = 485, FN = 113\n",
            "EM Accuracy : 0.1038961038961039\n",
            "DS Accuracy : 0.7600998669772954\n",
            "Micro F1    : 0.061118749187268104\n",
            "Macro F1 Score = 0.13583815028901733\n",
            "***************************************************************\n",
            "predicting_ Epoch : 17\n",
            "Number of Test sentences : 77\n",
            "TP = 53, TN = 1710,FP = 554, FN = 107\n",
            "EM Accuracy : 0.11688311688311688\n",
            "DS Accuracy : 0.7441303307782908\n",
            "Micro F1    : 0.07934656156847121\n",
            "Macro F1 Score = 0.13820078226857888\n",
            "***************************************************************\n",
            "predicting_ Epoch : 18\n",
            "Number of Test sentences : 77\n",
            "TP = 41, TN = 1804,FP = 460, FN = 119\n",
            "EM Accuracy : 0.1038961038961039\n",
            "DS Accuracy : 0.766506331287299\n",
            "Micro F1    : 0.0540421471681498\n",
            "Macro F1 Score = 0.12405446293494705\n",
            "***************************************************************\n",
            "predicting_ Epoch : 19\n",
            "Number of Test sentences : 77\n",
            "TP = 50, TN = 1680,FP = 584, FN = 110\n",
            "EM Accuracy : 0.14285714285714285\n",
            "DS Accuracy : 0.733809811110586\n",
            "Micro F1    : 0.06561810207547884\n",
            "Macro F1 Score = 0.12594458438287154\n",
            "***************************************************************\n",
            "predicting_ Epoch : 20\n",
            "Number of Test sentences : 77\n",
            "TP = 45, TN = 1772,FP = 492, FN = 115\n",
            "EM Accuracy : 0.1038961038961039\n",
            "DS Accuracy : 0.7611699209811607\n",
            "Micro F1    : 0.06174884947057895\n",
            "Macro F1 Score = 0.1291248206599713\n",
            "***************************************************************\n",
            "predicting_ Epoch : 21\n",
            "Number of Test sentences : 77\n",
            "TP = 53, TN = 1758,FP = 506, FN = 107\n",
            "EM Accuracy : 0.1038961038961039\n",
            "DS Accuracy : 0.7508553528572921\n",
            "Micro F1    : 0.13700269364985257\n",
            "Macro F1 Score = 0.1474269819193324\n",
            "***************************************************************\n",
            "predicting_ Epoch : 22\n",
            "Number of Test sentences : 77\n",
            "TP = 56, TN = 1714,FP = 550, FN = 104\n",
            "EM Accuracy : 0.1038961038961039\n",
            "DS Accuracy : 0.7399819810602457\n",
            "Micro F1    : 0.13092811370369783\n",
            "Macro F1 Score = 0.1462140992167102\n",
            "***************************************************************\n",
            "predicting_ Epoch : 23\n",
            "Number of Test sentences : 77\n",
            "TP = 57, TN = 1703,FP = 561, FN = 103\n",
            "EM Accuracy : 0.11688311688311688\n",
            "DS Accuracy : 0.737496692790841\n",
            "Micro F1    : 0.11706745985847475\n",
            "Macro F1 Score = 0.14652956298200515\n",
            "***************************************************************\n",
            "predicting_ Epoch : 24\n",
            "Number of Test sentences : 77\n",
            "TP = 61, TN = 1623,FP = 641, FN = 99\n",
            "EM Accuracy : 0.15584415584415584\n",
            "DS Accuracy : 0.7135771229835726\n",
            "Micro F1    : 0.11781378922683766\n",
            "Macro F1 Score = 0.14153132250580047\n",
            "***************************************************************\n",
            "predicting_ Epoch : 25\n",
            "Number of Test sentences : 77\n",
            "TP = 65, TN = 1579,FP = 685, FN = 95\n",
            "EM Accuracy : 0.11688311688311688\n",
            "DS Accuracy : 0.6960312875824589\n",
            "Micro F1    : 0.14079298964494752\n",
            "Macro F1 Score = 0.14285714285714285\n",
            "***************************************************************\n",
            "predicting_ Epoch : 26\n",
            "Number of Test sentences : 77\n",
            "TP = 58, TN = 1660,FP = 604, FN = 102\n",
            "EM Accuracy : 0.11688311688311688\n",
            "DS Accuracy : 0.7135632855141081\n",
            "Micro F1    : 0.12985305226983074\n",
            "Macro F1 Score = 0.1411192214111922\n",
            "***************************************************************\n",
            "predicting_ Epoch : 27\n",
            "Number of Test sentences : 77\n",
            "TP = 58, TN = 1694,FP = 570, FN = 102\n",
            "EM Accuracy : 0.15584415584415584\n",
            "DS Accuracy : 0.7239379880671052\n",
            "Micro F1    : 0.1356925182002329\n",
            "Macro F1 Score = 0.14720812182741116\n",
            "***************************************************************\n",
            "predicting_ Epoch : 28\n",
            "Number of Test sentences : 77\n",
            "TP = 59, TN = 1651,FP = 613, FN = 101\n",
            "EM Accuracy : 0.11688311688311688\n",
            "DS Accuracy : 0.70147728724707\n",
            "Micro F1    : 0.15462968499759383\n",
            "Macro F1 Score = 0.14182692307692307\n",
            "***************************************************************\n",
            "predicting_ Epoch : 29\n",
            "Number of Test sentences : 77\n",
            "TP = 61, TN = 1665,FP = 599, FN = 99\n",
            "EM Accuracy : 0.12987012987012986\n",
            "DS Accuracy : 0.7080046881161356\n",
            "Micro F1    : 0.15761959736781178\n",
            "Macro F1 Score = 0.14878048780487804\n",
            "Saved model to disk\n",
            "Fold 2\n",
            "147 77\n",
            "151 73\n",
            "Starting Epochs\n",
            "***************************************************************\n",
            "predicting_ Epoch : 0\n",
            "Number of Test sentences : 73\n",
            "TP = 82, TN = 685,FP = 1363, FN = 48\n",
            "EM Accuracy : 0.0273972602739726\n",
            "DS Accuracy : 0.3593153328173732\n",
            "Micro F1    : 0.10756343580577349\n",
            "Macro F1 Score = 0.10412698412698412\n",
            "***************************************************************\n",
            "predicting_ Epoch : 1\n",
            "Number of Test sentences : 73\n",
            "TP = 84, TN = 854,FP = 1194, FN = 46\n",
            "EM Accuracy : 0.0410958904109589\n",
            "DS Accuracy : 0.406056216422164\n",
            "Micro F1    : 0.11647697282358836\n",
            "Macro F1 Score = 0.11931818181818182\n",
            "***************************************************************\n",
            "predicting_ Epoch : 2\n",
            "Number of Test sentences : 73\n",
            "TP = 69, TN = 1066,FP = 982, FN = 61\n",
            "EM Accuracy : 0.0136986301369863\n",
            "DS Accuracy : 0.4726947062692106\n",
            "Micro F1    : 0.11078849352832812\n",
            "Macro F1 Score = 0.11685012701100762\n",
            "***************************************************************\n",
            "predicting_ Epoch : 3\n",
            "Number of Test sentences : 73\n",
            "TP = 71, TN = 1109,FP = 939, FN = 59\n",
            "EM Accuracy : 0.0\n",
            "DS Accuracy : 0.4833327029037982\n",
            "Micro F1    : 0.11802518951780946\n",
            "Macro F1 Score = 0.12456140350877193\n",
            "***************************************************************\n",
            "predicting_ Epoch : 4\n",
            "Number of Test sentences : 73\n",
            "TP = 68, TN = 1130,FP = 918, FN = 62\n",
            "EM Accuracy : 0.0\n",
            "DS Accuracy : 0.4833024657446783\n",
            "Micro F1    : 0.11796168227852094\n",
            "Macro F1 Score = 0.12186379928315412\n",
            "***************************************************************\n",
            "predicting_ Epoch : 5\n",
            "Number of Test sentences : 73\n",
            "TP = 74, TN = 1081,FP = 967, FN = 56\n",
            "EM Accuracy : 0.0\n",
            "DS Accuracy : 0.46039800026916866\n",
            "Micro F1    : 0.12059335651813644\n",
            "Macro F1 Score = 0.1263877028181042\n",
            "***************************************************************\n",
            "predicting_ Epoch : 6\n",
            "Number of Test sentences : 73\n",
            "TP = 76, TN = 1040,FP = 1008, FN = 54\n",
            "EM Accuracy : 0.0\n",
            "DS Accuracy : 0.435394237657387\n",
            "Micro F1    : 0.11718453380339972\n",
            "Macro F1 Score = 0.12520593080724876\n",
            "***************************************************************\n",
            "predicting_ Epoch : 7\n",
            "Number of Test sentences : 73\n",
            "TP = 79, TN = 1046,FP = 1002, FN = 51\n",
            "EM Accuracy : 0.0273972602739726\n",
            "DS Accuracy : 0.43115646207713176\n",
            "Micro F1    : 0.1254346699472416\n",
            "Macro F1 Score = 0.13047068538398018\n",
            "***************************************************************\n",
            "predicting_ Epoch : 8\n",
            "Number of Test sentences : 73\n",
            "TP = 79, TN = 1085,FP = 963, FN = 51\n",
            "EM Accuracy : 0.0273972602739726\n",
            "DS Accuracy : 0.4479110975914602\n",
            "Micro F1    : 0.12640838116421932\n",
            "Macro F1 Score = 0.1348122866894198\n",
            "***************************************************************\n",
            "predicting_ Epoch : 9\n",
            "Number of Test sentences : 73\n",
            "TP = 80, TN = 1079,FP = 969, FN = 50\n",
            "EM Accuracy : 0.0273972602739726\n",
            "DS Accuracy : 0.438449088375635\n",
            "Micro F1    : 0.12707769344132586\n",
            "Macro F1 Score = 0.13570822731128074\n",
            "***************************************************************\n",
            "predicting_ Epoch : 10\n",
            "Number of Test sentences : 73\n",
            "TP = 81, TN = 1039,FP = 1009, FN = 49\n",
            "EM Accuracy : 0.0\n",
            "DS Accuracy : 0.41942397803675685\n",
            "Micro F1    : 0.1258069510955218\n",
            "Macro F1 Score = 0.13278688524590163\n",
            "***************************************************************\n",
            "predicting_ Epoch : 11\n",
            "Number of Test sentences : 73\n",
            "TP = 79, TN = 1033,FP = 1015, FN = 51\n",
            "EM Accuracy : 0.0\n",
            "DS Accuracy : 0.4241398999560673\n",
            "Micro F1    : 0.1271150038685908\n",
            "Macro F1 Score = 0.12908496732026145\n",
            "***************************************************************\n",
            "predicting_ Epoch : 12\n",
            "Number of Test sentences : 73\n",
            "TP = 76, TN = 1160,FP = 888, FN = 54\n",
            "EM Accuracy : 0.0136986301369863\n",
            "DS Accuracy : 0.4912831739745567\n",
            "Micro F1    : 0.1390857468763011\n",
            "Macro F1 Score = 0.13893967093235832\n",
            "***************************************************************\n",
            "predicting_ Epoch : 13\n",
            "Number of Test sentences : 73\n",
            "TP = 72, TN = 1174,FP = 874, FN = 58\n",
            "EM Accuracy : 0.0136986301369863\n",
            "DS Accuracy : 0.49711586931103824\n",
            "Micro F1    : 0.1363126144225114\n",
            "Macro F1 Score = 0.13382899628252787\n",
            "***************************************************************\n",
            "predicting_ Epoch : 14\n",
            "Number of Test sentences : 73\n",
            "TP = 69, TN = 1231,FP = 817, FN = 61\n",
            "EM Accuracy : 0.0273972602739726\n",
            "DS Accuracy : 0.5254506981281928\n",
            "Micro F1    : 0.13296992102856564\n",
            "Macro F1 Score = 0.13582677165354332\n",
            "***************************************************************\n",
            "predicting_ Epoch : 15\n",
            "Number of Test sentences : 73\n",
            "TP = 68, TN = 1215,FP = 833, FN = 62\n",
            "EM Accuracy : 0.0136986301369863\n",
            "DS Accuracy : 0.5250289365913755\n",
            "Micro F1    : 0.1321501364794433\n",
            "Macro F1 Score = 0.13191076624636275\n",
            "***************************************************************\n",
            "predicting_ Epoch : 16\n",
            "Number of Test sentences : 73\n",
            "TP = 74, TN = 1128,FP = 920, FN = 56\n",
            "EM Accuracy : 0.0410958904109589\n",
            "DS Accuracy : 0.483484616167252\n",
            "Micro F1    : 0.13032471485490776\n",
            "Macro F1 Score = 0.13167259786476868\n",
            "***************************************************************\n",
            "predicting_ Epoch : 17\n",
            "Number of Test sentences : 73\n",
            "TP = 63, TN = 1273,FP = 775, FN = 67\n",
            "EM Accuracy : 0.0273972602739726\n",
            "DS Accuracy : 0.555651827787376\n",
            "Micro F1    : 0.12863237163458757\n",
            "Macro F1 Score = 0.13016528925619836\n",
            "***************************************************************\n",
            "predicting_ Epoch : 18\n",
            "Number of Test sentences : 73\n",
            "TP = 61, TN = 1370,FP = 678, FN = 69\n",
            "EM Accuracy : 0.0136986301369863\n",
            "DS Accuracy : 0.6044872384898339\n",
            "Micro F1    : 0.13701843575875736\n",
            "Macro F1 Score = 0.14039125431530494\n",
            "***************************************************************\n",
            "predicting_ Epoch : 19\n",
            "Number of Test sentences : 73\n",
            "TP = 67, TN = 1291,FP = 757, FN = 63\n",
            "EM Accuracy : 0.0273972602739726\n",
            "DS Accuracy : 0.5686189985950615\n",
            "Micro F1    : 0.1372156967295333\n",
            "Macro F1 Score = 0.14046121593291405\n",
            "***************************************************************\n",
            "predicting_ Epoch : 20\n",
            "Number of Test sentences : 73\n",
            "TP = 66, TN = 1309,FP = 739, FN = 64\n",
            "EM Accuracy : 0.0273972602739726\n",
            "DS Accuracy : 0.5846442280439259\n",
            "Micro F1    : 0.13808309718149603\n",
            "Macro F1 Score = 0.1411764705882353\n",
            "***************************************************************\n",
            "predicting_ Epoch : 21\n",
            "Number of Test sentences : 73\n",
            "TP = 68, TN = 1280,FP = 768, FN = 62\n",
            "EM Accuracy : 0.0273972602739726\n",
            "DS Accuracy : 0.5611000115847455\n",
            "Micro F1    : 0.1359114641737079\n",
            "Macro F1 Score = 0.14078674948240166\n",
            "***************************************************************\n",
            "predicting_ Epoch : 22\n",
            "Number of Test sentences : 73\n",
            "TP = 57, TN = 1412,FP = 636, FN = 73\n",
            "EM Accuracy : 0.0136986301369863\n",
            "DS Accuracy : 0.6344515110990533\n",
            "Micro F1    : 0.13526022321072997\n",
            "Macro F1 Score = 0.1385176184690158\n",
            "***************************************************************\n",
            "predicting_ Epoch : 23\n",
            "Number of Test sentences : 73\n",
            "TP = 60, TN = 1351,FP = 697, FN = 70\n",
            "EM Accuracy : 0.0136986301369863\n",
            "DS Accuracy : 0.6064970554694464\n",
            "Micro F1    : 0.12462236329329997\n",
            "Macro F1 Score = 0.13528748590755355\n",
            "***************************************************************\n",
            "predicting_ Epoch : 24\n",
            "Number of Test sentences : 73\n",
            "TP = 59, TN = 1390,FP = 658, FN = 71\n",
            "EM Accuracy : 0.0273972602739726\n",
            "DS Accuracy : 0.6230631643377448\n",
            "Micro F1    : 0.12697726409427568\n",
            "Macro F1 Score = 0.13931523022432113\n",
            "***************************************************************\n",
            "predicting_ Epoch : 25\n",
            "Number of Test sentences : 73\n",
            "TP = 56, TN = 1412,FP = 636, FN = 74\n",
            "EM Accuracy : 0.0136986301369863\n",
            "DS Accuracy : 0.6374790824771842\n",
            "Micro F1    : 0.1274675519876297\n",
            "Macro F1 Score = 0.1362530413625304\n",
            "***************************************************************\n",
            "predicting_ Epoch : 26\n",
            "Number of Test sentences : 73\n",
            "TP = 55, TN = 1443,FP = 605, FN = 75\n",
            "EM Accuracy : 0.0410958904109589\n",
            "DS Accuracy : 0.6537895500516782\n",
            "Micro F1    : 0.12739451437736757\n",
            "Macro F1 Score = 0.13924050632911392\n",
            "***************************************************************\n",
            "predicting_ Epoch : 27\n",
            "Number of Test sentences : 73\n",
            "TP = 55, TN = 1464,FP = 584, FN = 75\n",
            "EM Accuracy : 0.0547945205479452\n",
            "DS Accuracy : 0.6607310852396187\n",
            "Micro F1    : 0.12916669809781472\n",
            "Macro F1 Score = 0.14304291287386217\n",
            "***************************************************************\n",
            "predicting_ Epoch : 28\n",
            "Number of Test sentences : 73\n",
            "TP = 53, TN = 1457,FP = 591, FN = 77\n",
            "EM Accuracy : 0.0547945205479452\n",
            "DS Accuracy : 0.6620177531285544\n",
            "Micro F1    : 0.12555594545254906\n",
            "Macro F1 Score = 0.13695090439276486\n",
            "***************************************************************\n",
            "predicting_ Epoch : 29\n",
            "Number of Test sentences : 73\n",
            "TP = 53, TN = 1473,FP = 575, FN = 77\n",
            "EM Accuracy : 0.0684931506849315\n",
            "DS Accuracy : 0.6760896557779735\n",
            "Micro F1    : 0.13222059171853548\n",
            "Macro F1 Score = 0.13984168865435356\n",
            "Saved model to disk\n",
            "Fold 3\n",
            "147 77\n",
            "150 74\n",
            "Starting Epochs\n",
            "***************************************************************\n",
            "predicting_ Epoch : 0\n",
            "Number of Test sentences : 74\n",
            "TP = 102, TN = 1151,FP = 1022, FN = 69\n",
            "EM Accuracy : 0.0\n",
            "DS Accuracy : 0.5313355528236573\n",
            "Micro F1    : 0.1299584179940429\n",
            "Macro F1 Score = 0.15752895752895754\n",
            "***************************************************************\n",
            "predicting_ Epoch : 1\n",
            "Number of Test sentences : 74\n",
            "TP = 95, TN = 1118,FP = 1055, FN = 76\n",
            "EM Accuracy : 0.0\n",
            "DS Accuracy : 0.41019232548092144\n",
            "Micro F1    : 0.10620188037740869\n",
            "Macro F1 Score = 0.14383043149129449\n",
            "***************************************************************\n",
            "predicting_ Epoch : 2\n",
            "Number of Test sentences : 74\n",
            "TP = 107, TN = 1062,FP = 1111, FN = 64\n",
            "EM Accuracy : 0.0\n",
            "DS Accuracy : 0.4101929580619074\n",
            "Micro F1    : 0.11237641508504762\n",
            "Macro F1 Score = 0.15406767458603313\n",
            "***************************************************************\n",
            "predicting_ Epoch : 3\n",
            "Number of Test sentences : 74\n",
            "TP = 109, TN = 1053,FP = 1120, FN = 62\n",
            "EM Accuracy : 0.0\n",
            "DS Accuracy : 0.3976068978012604\n",
            "Micro F1    : 0.11483563647920184\n",
            "Macro F1 Score = 0.15571428571428572\n",
            "***************************************************************\n",
            "predicting_ Epoch : 4\n",
            "Number of Test sentences : 74\n",
            "TP = 105, TN = 1085,FP = 1088, FN = 66\n",
            "EM Accuracy : 0.02702702702702703\n",
            "DS Accuracy : 0.4035136725486028\n",
            "Micro F1    : 0.11008066886885806\n",
            "Macro F1 Score = 0.15395894428152493\n",
            "***************************************************************\n",
            "predicting_ Epoch : 5\n",
            "Number of Test sentences : 74\n",
            "TP = 105, TN = 1124,FP = 1049, FN = 66\n",
            "EM Accuracy : 0.02702702702702703\n",
            "DS Accuracy : 0.4054104124193182\n",
            "Micro F1    : 0.10193692830069695\n",
            "Macro F1 Score = 0.15849056603773584\n",
            "***************************************************************\n",
            "predicting_ Epoch : 6\n",
            "Number of Test sentences : 74\n",
            "TP = 92, TN = 1162,FP = 1011, FN = 79\n",
            "EM Accuracy : 0.08108108108108109\n",
            "DS Accuracy : 0.4208807882916758\n",
            "Micro F1    : 0.09162641469439271\n",
            "Macro F1 Score = 0.14442700156985872\n",
            "***************************************************************\n",
            "predicting_ Epoch : 7\n",
            "Number of Test sentences : 74\n",
            "TP = 71, TN = 1406,FP = 767, FN = 100\n",
            "EM Accuracy : 0.08108108108108109\n",
            "DS Accuracy : 0.47802470219391835\n",
            "Micro F1    : 0.09503628725760403\n",
            "Macro F1 Score = 0.14073339940535184\n",
            "***************************************************************\n",
            "predicting_ Epoch : 8\n",
            "Number of Test sentences : 74\n",
            "TP = 60, TN = 1467,FP = 706, FN = 111\n",
            "EM Accuracy : 0.05405405405405406\n",
            "DS Accuracy : 0.5131323711294059\n",
            "Micro F1    : 0.09882530473360294\n",
            "Macro F1 Score = 0.128068303094984\n",
            "***************************************************************\n",
            "predicting_ Epoch : 9\n",
            "Number of Test sentences : 74\n",
            "TP = 59, TN = 1484,FP = 689, FN = 112\n",
            "EM Accuracy : 0.08108108108108109\n",
            "DS Accuracy : 0.5080635979666112\n",
            "Micro F1    : 0.09247469481054409\n",
            "Macro F1 Score = 0.12840043525571274\n",
            "***************************************************************\n",
            "predicting_ Epoch : 10\n",
            "Number of Test sentences : 74\n",
            "TP = 60, TN = 1490,FP = 683, FN = 111\n",
            "EM Accuracy : 0.08108108108108109\n",
            "DS Accuracy : 0.5055847695828224\n",
            "Micro F1    : 0.09657238787034184\n",
            "Macro F1 Score = 0.13129102844638948\n",
            "***************************************************************\n",
            "predicting_ Epoch : 11\n",
            "Number of Test sentences : 74\n",
            "TP = 54, TN = 1473,FP = 700, FN = 117\n",
            "EM Accuracy : 0.0945945945945946\n",
            "DS Accuracy : 0.4955710712559538\n",
            "Micro F1    : 0.08251431248708925\n",
            "Macro F1 Score = 0.11675675675675676\n",
            "***************************************************************\n",
            "predicting_ Epoch : 12\n",
            "Number of Test sentences : 74\n",
            "TP = 56, TN = 1481,FP = 692, FN = 115\n",
            "EM Accuracy : 0.06756756756756757\n",
            "DS Accuracy : 0.5015048251076242\n",
            "Micro F1    : 0.09056903971866695\n",
            "Macro F1 Score = 0.12187159956474429\n",
            "***************************************************************\n",
            "predicting_ Epoch : 13\n",
            "Number of Test sentences : 74\n",
            "TP = 52, TN = 1490,FP = 683, FN = 119\n",
            "EM Accuracy : 0.08108108108108109\n",
            "DS Accuracy : 0.5027570690772237\n",
            "Micro F1    : 0.08090322264945479\n",
            "Macro F1 Score = 0.11479028697571744\n",
            "***************************************************************\n",
            "predicting_ Epoch : 14\n",
            "Number of Test sentences : 74\n",
            "TP = 52, TN = 1503,FP = 670, FN = 119\n",
            "EM Accuracy : 0.05405405405405406\n",
            "DS Accuracy : 0.5126711682388969\n",
            "Micro F1    : 0.07992027610448663\n",
            "Macro F1 Score = 0.11646136618141098\n",
            "***************************************************************\n",
            "predicting_ Epoch : 15\n",
            "Number of Test sentences : 74\n",
            "TP = 61, TN = 1440,FP = 733, FN = 110\n",
            "EM Accuracy : 0.04054054054054054\n",
            "DS Accuracy : 0.4960411758962097\n",
            "Micro F1    : 0.09576889295104753\n",
            "Macro F1 Score = 0.12642487046632125\n",
            "***************************************************************\n",
            "predicting_ Epoch : 16\n",
            "Number of Test sentences : 74\n",
            "TP = 56, TN = 1475,FP = 698, FN = 115\n",
            "EM Accuracy : 0.08108108108108109\n",
            "DS Accuracy : 0.5036380300534732\n",
            "Micro F1    : 0.08501062551372149\n",
            "Macro F1 Score = 0.12108108108108108\n",
            "***************************************************************\n",
            "predicting_ Epoch : 17\n",
            "Number of Test sentences : 74\n",
            "TP = 57, TN = 1454,FP = 719, FN = 114\n",
            "EM Accuracy : 0.08108108108108109\n",
            "DS Accuracy : 0.49802714248504804\n",
            "Micro F1    : 0.08643866842628885\n",
            "Macro F1 Score = 0.12038014783526928\n",
            "***************************************************************\n",
            "predicting_ Epoch : 18\n",
            "Number of Test sentences : 74\n",
            "TP = 53, TN = 1553,FP = 620, FN = 118\n",
            "EM Accuracy : 0.0945945945945946\n",
            "DS Accuracy : 0.533176296747656\n",
            "Micro F1    : 0.08899842355598708\n",
            "Macro F1 Score = 0.12559241706161137\n",
            "***************************************************************\n",
            "predicting_ Epoch : 19\n",
            "Number of Test sentences : 74\n",
            "TP = 48, TN = 1542,FP = 631, FN = 123\n",
            "EM Accuracy : 0.05405405405405406\n",
            "DS Accuracy : 0.535569913489555\n",
            "Micro F1    : 0.07818194997761559\n",
            "Macro F1 Score = 0.11294117647058824\n",
            "***************************************************************\n",
            "predicting_ Epoch : 20\n",
            "Number of Test sentences : 74\n",
            "TP = 52, TN = 1564,FP = 609, FN = 119\n",
            "EM Accuracy : 0.05405405405405406\n",
            "DS Accuracy : 0.545932894198374\n",
            "Micro F1    : 0.08603903550497977\n",
            "Macro F1 Score = 0.125\n",
            "***************************************************************\n",
            "predicting_ Epoch : 21\n",
            "Number of Test sentences : 74\n",
            "TP = 54, TN = 1593,FP = 580, FN = 117\n",
            "EM Accuracy : 0.0945945945945946\n",
            "DS Accuracy : 0.5676769478124971\n",
            "Micro F1    : 0.08968707726314216\n",
            "Macro F1 Score = 0.1341614906832298\n",
            "***************************************************************\n",
            "predicting_ Epoch : 22\n",
            "Number of Test sentences : 74\n",
            "TP = 55, TN = 1522,FP = 651, FN = 116\n",
            "EM Accuracy : 0.06756756756756757\n",
            "DS Accuracy : 0.5432038598769607\n",
            "Micro F1    : 0.09110028015600773\n",
            "Macro F1 Score = 0.12542759407069556\n",
            "***************************************************************\n",
            "predicting_ Epoch : 23\n",
            "Number of Test sentences : 74\n",
            "TP = 60, TN = 1517,FP = 656, FN = 111\n",
            "EM Accuracy : 0.05405405405405406\n",
            "DS Accuracy : 0.5314473149320594\n",
            "Micro F1    : 0.09249001892684672\n",
            "Macro F1 Score = 0.13528748590755355\n",
            "***************************************************************\n",
            "predicting_ Epoch : 24\n",
            "Number of Test sentences : 74\n",
            "TP = 58, TN = 1537,FP = 636, FN = 113\n",
            "EM Accuracy : 0.06756756756756757\n",
            "DS Accuracy : 0.5430787263011905\n",
            "Micro F1    : 0.08926620954353548\n",
            "Macro F1 Score = 0.13410404624277455\n",
            "***************************************************************\n",
            "predicting_ Epoch : 25\n",
            "Number of Test sentences : 74\n",
            "TP = 57, TN = 1602,FP = 571, FN = 114\n",
            "EM Accuracy : 0.08108108108108109\n",
            "DS Accuracy : 0.5894262936647816\n",
            "Micro F1    : 0.09786597112181612\n",
            "Macro F1 Score = 0.14267834793491865\n",
            "***************************************************************\n",
            "predicting_ Epoch : 26\n",
            "Number of Test sentences : 74\n",
            "TP = 59, TN = 1609,FP = 564, FN = 112\n",
            "EM Accuracy : 0.0945945945945946\n",
            "DS Accuracy : 0.5959329007838516\n",
            "Micro F1    : 0.1078183564998981\n",
            "Macro F1 Score = 0.1486146095717884\n",
            "***************************************************************\n",
            "predicting_ Epoch : 27\n",
            "Number of Test sentences : 74\n",
            "TP = 55, TN = 1599,FP = 574, FN = 116\n",
            "EM Accuracy : 0.06756756756756757\n",
            "DS Accuracy : 0.5896601484549084\n",
            "Micro F1    : 0.0957166618931325\n",
            "Macro F1 Score = 0.1375\n",
            "***************************************************************\n",
            "predicting_ Epoch : 28\n",
            "Number of Test sentences : 74\n",
            "TP = 57, TN = 1588,FP = 585, FN = 114\n",
            "EM Accuracy : 0.08108108108108109\n",
            "DS Accuracy : 0.5895497760397742\n",
            "Micro F1    : 0.09663297355995125\n",
            "Macro F1 Score = 0.14022140221402213\n",
            "***************************************************************\n",
            "predicting_ Epoch : 29\n",
            "Number of Test sentences : 74\n",
            "TP = 55, TN = 1654,FP = 519, FN = 116\n",
            "EM Accuracy : 0.0945945945945946\n",
            "DS Accuracy : 0.6272987107090949\n",
            "Micro F1    : 0.10897519185120305\n",
            "Macro F1 Score = 0.1476510067114094\n",
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}