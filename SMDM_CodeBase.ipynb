{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SMDM CodeBase.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5DA7c0VKSYX"
      },
      "source": [
        "**Sarcasm Target Detection Codebase**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "f_dmEBsSBf8M",
        "outputId": "d218615f-45ec-4918-a561-44b54c650b3d"
      },
      "source": [
        "# Upload 'snippets.xlsx' from the local file system.\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a499be93-5fd7-4f42-91fe-652eeb46004d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a499be93-5fd7-4f42-91fe-652eeb46004d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving snippets.xlsx to snippets.xlsx\n",
            "User uploaded file \"snippets.xlsx\" with length 28003 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lu-Fvr38C2Ho",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eeee3f63-2aea-48fc-edf4-2ceb7aaa7ac6"
      },
      "source": [
        "# Mount google drive to use 'crawl-300d-2M.vec'. \n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0EM5zoFdT35O",
        "outputId": "26c6baf3-fc44-4d7a-a144-fcab7bae5e2c"
      },
      "source": [
        "!pip install empath"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting empath\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d2/84/a5de61a99252f60d705d7982b3648db517a704c89fa7629d3d3637a6e604/empath-0.89.tar.gz (57kB)\n",
            "\r\u001b[K     |█████▊                          | 10kB 16.4MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 20kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 30kB 7.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 40kB 6.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 51kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 3.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from empath) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->empath) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->empath) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->empath) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->empath) (1.24.3)\n",
            "Building wheels for collected packages: empath\n",
            "  Building wheel for empath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for empath: filename=empath-0.89-cp37-none-any.whl size=57824 sha256=67ad9b352b747992cf419e259cb6fec9f8dc3a4ede1e53c77b4181a576f90dc7\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/ea/2f/2bc54d4f9985ce61753ebc5b00cb2df51d855589267c667308\n",
            "Successfully built empath\n",
            "Installing collected packages: empath\n",
            "Successfully installed empath-0.89\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LweGufCtKzba"
      },
      "source": [
        "# Import basic maths and processing libraries.\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# A RegexpTokenizer splits a string into substrings using a regular expression.\n",
        "from nltk.tokenize import RegexpTokenizer \n",
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "\n",
        "from keras.layers import Dense ,LSTM,concatenate,Input,Flatten\n",
        "from keras.models import Model\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "from nltk.tag import StanfordPOSTagger\n",
        "from nltk.tag import StanfordNERTagger\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from empath import Empath\n",
        "\n",
        "import pickle\n",
        "import codecs\n",
        "from collections import deque"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2npgiN0QQNS"
      },
      "source": [
        "tokenizer = RegexpTokenizer(r'\\w+') # try removing r\n",
        "detokenizer = TreebankWordDetokenizer()\n",
        "# Excel file contains no header column and names gives custom column names\n",
        "df = pd.read_excel(\"snippets.xlsx\", sheet_name=None, header=None, names=['Snippet','target'])\n",
        "df = df['Sheet1']\n",
        "embedding_file = '/gdrive/MyDrive/crawl-300d-2M.vec'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggbf5YYgjyQI"
      },
      "source": [
        "def clearLine(line):\n",
        "  cleanedLine = ''\n",
        "  for letter in line:\n",
        "    if letter == '?' or letter == '!' or letter == ',' or letter == '\"' or letter == '-' or letter == ';' or letter == '.' or ord(letter) > 255 :\n",
        "      cleanedLine += ' '\n",
        "    else:\n",
        "      cleanedLine += letter\n",
        "  return cleanedLine"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQlSp4C5TtL1"
      },
      "source": [
        "def loadEmbed():\n",
        "    print('loading word embeddings...')\n",
        "    embeddings_index = {}\n",
        "    f = codecs.open(embedding_file, encoding='utf-8')\n",
        "    for line in f:\n",
        "        # Line has the format : Word val1 val2 val3 ..... val300\n",
        "        values = line.rstrip().rsplit(' ')\n",
        "        word = values[0]\n",
        "        coefs = np.asarray(values[1:], dtype='float32')\n",
        "        embeddings_index[word] = coefs\n",
        "    f.close()\n",
        "    print('found %s word vectors' % len(embeddings_index))\n",
        "    return embeddings_index"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cv6yMkNMgP9u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcf490ea-f9a3-4c60-d5b9-152484aefcc6"
      },
      "source": [
        "# Loading pre-trained embeddings\n",
        "model=loadEmbed()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading word embeddings...\n",
            "found 1999996 word vectors\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPext8rQigyp"
      },
      "source": [
        "# Stores all distinct words in the dataset.\n",
        "all_words=[]\n",
        "\n",
        "for i in range(len(df['Snippet'])):\n",
        "    line = clearLine(df['Snippet'][i])\n",
        "    all_words.extend(line.split())\n",
        "\n",
        "# get all unique words from the dataset\n",
        "all_words=list(dict.fromkeys(all_words))\n",
        "\n",
        "# make all words to lowercase\n",
        "all_words=[x.lower() for x in all_words]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yC4I9QzPiomu"
      },
      "source": [
        "# Stores the vector representations of the words from the dataset.\n",
        "embeddings={}\n",
        "for each in all_words:\n",
        "    # Get vectors for words in the dataset\n",
        "    if each not in model.keys(): \n",
        "        embeddings[each]=model['unk']\n",
        "    else:\n",
        "        embeddings[each]=model[each]\n",
        "\n",
        "embeddings['<pad>'] = [0]*300\n",
        "embeddings['<start>'] = model[\"start\"]\n",
        "embeddings['<end>'] = model[\"end\"]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FzhEcqOI0Cq"
      },
      "source": [
        "# Prepare the left context, right context, and candidate word from the dataset.\n",
        "# Pre-Processed Data (ppd)\n",
        "\n",
        "ppd = {}\n",
        "ppd['left_context'] = []\n",
        "ppd['right_context'] = []\n",
        "ppd['Candidate_word'] = []\n",
        "ppd['target_status'] = []\n",
        "\n",
        "for i in range(len(df['Snippet'])):\n",
        "  line = clearLine(df['Snippet'][i].lower());\n",
        "  line = line.split()\n",
        "  targetList = df['target'][i].lower().split(\",\")\n",
        "  targetWord = []\n",
        "  for tl in targetList:\n",
        "    targetWord.extend(tl.split())\n",
        "  \n",
        "  for i in range(len(line)):\n",
        "    word = line[i]\n",
        "    ppd['Candidate_word'].append(word)\n",
        "    ppd['left_context'].append([\"<start>\"] + line[:i])\n",
        "    ppd['right_context'].append(line[i+1:] + [\"<end>\"])\n",
        "    ppd['target_status'].append(int(word in targetWord))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ov65vnKME1Wv"
      },
      "source": [
        "# Embedding Left Context\n",
        "keras_left_context = []\n",
        "for i in range(len(ppd['left_context'])):\n",
        "    one_vector = []\n",
        "    temp = ppd['left_context'][i]\n",
        "    for m in temp:\n",
        "        one_vector.append(embeddings[m])\n",
        "    one_vector.extend([embeddings['<pad>'] for x in range(78 - len(ppd['left_context'][i]))])\n",
        "    keras_left_context.append(one_vector)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjUxOeBUH49B"
      },
      "source": [
        "# Embedding Right Context \n",
        "keras_right_context = []\n",
        "for i in range(len(ppd['right_context'])):\n",
        "    one_vector = []\n",
        "    temp = ppd['right_context'][i]\n",
        "    for m in temp:\n",
        "        one_vector.append(embeddings[m])\n",
        "    one_vector.extend([embeddings['<pad>'] for x in range(78 - len(ppd['right_context'][i]))])\n",
        "    keras_right_context.append(one_vector)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5ehP344Ic1y"
      },
      "source": [
        "# Embedding Candidate Word\n",
        "keras_middle = []\n",
        "for i in range(len(ppd['Candidate_word'])):\n",
        "    keras_middle.append(embeddings[ppd['Candidate_word'][i]])\n",
        "\n",
        "labels = ppd['target_status']"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Won77S-7IypK"
      },
      "source": [
        "#Saving the processed dataset in a pickle file\n",
        "# f = open(b\"Data_fast.pkl\",\"wb\")\n",
        "# pickle.dump(zip(keras_left_context,keras_right_context,keras_middle,ppd['target_status']),f)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62vxErvmRAFA"
      },
      "source": [
        "Socio-Linguistic Feature Extraction\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17MyiJkvRG6u"
      },
      "source": [
        "ohe=OneHotEncoder()\n",
        "lb=LabelEncoder()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ColM0MMZRMAo",
        "outputId": "e25ebca2-f35c-4803-8de6-86bc89e7dca5"
      },
      "source": [
        "# Using Stanford POS Tagger API\n",
        "jar = '/gdrive/MyDrive/features/stanford-postagger-3.9.2.jar'\n",
        "model = '/gdrive/MyDrive/features/english-left3words-distsim.tagger'\n",
        "pos_tagger = StanfordPOSTagger(model, jar, encoding='utf8')\n",
        "\n",
        "# Extracting POS Features\n",
        "POS_snippets=[]\n",
        "for i in range(len(df['Snippet'])):\n",
        "    # think about .lower()\n",
        "    POS_snippets.extend(pos_tagger.tag(clearLine(df['Snippet'][i]).lower().split()))\n",
        "POS_snippets_type=[x[1] for x in POS_snippets]\n",
        "POS_snippets_type=lb.fit_transform(POS_snippets_type)\t\n",
        "pos_vec=ohe.fit_transform(np.reshape(POS_snippets_type,(-1, 1)))\n",
        "pos_vec=pos_vec.todense()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/tag/stanford.py:149: DeprecationWarning: \n",
            "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
            "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
            "  super(StanfordPOSTagger, self).__init__(*args, **kwargs)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1go53RTPRMev",
        "outputId": "94c0c4c7-3a4f-4f28-fd11-e88ffd5bc0a0"
      },
      "source": [
        "# Using Stanford NER Tagger API\n",
        "jar_n = '/gdrive/MyDrive/features/stanford-ner-3.9.2.jar'\n",
        "model_n = '/gdrive/MyDrive/features/english.all.3class.distsim.crf.ser.gz'\n",
        "ner_tagger = StanfordNERTagger(model_n, jar_n, encoding='utf8')\n",
        "\n",
        "# Extracting NER Features\n",
        "ner_snippets=[]\n",
        "for i in range(len(df['Snippet'])):\n",
        "    ner_snippets.extend(ner_tagger.tag(clearLine(df['Snippet'][i]).lower().split()))\n",
        "ner_snippets_type=[x[1] for x in ner_snippets]\n",
        "ner_snippets_type=lb.fit_transform(ner_snippets_type)\t\n",
        "ner_vec=ohe.fit_transform(np.reshape(ner_snippets_type,(-1, 1)))\n",
        "ner_vec=ner_vec.todense()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/tag/stanford.py:183: DeprecationWarning: \n",
            "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
            "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
            "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UE3JWgnYRNMu"
      },
      "source": [
        "# Extracting Empath Features\n",
        "lexicon = Empath()\n",
        "empath_vec=[]\n",
        "for text in ppd['Candidate_word']:\n",
        "    a=lexicon.analyze(text, normalize=True)\n",
        "    bv=[]\n",
        "    for i in a.values():\n",
        "        bv.append(i)\n",
        "    empath_vec.append(bv)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28iw-AYwJCHr"
      },
      "source": [
        "Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iN1wcrRWKt8E"
      },
      "source": [
        "# Function to group together candidate-words belonging to the same line.\n",
        "def compress():\n",
        "    lengths = []\n",
        "    for i in range (1,len(ppd['left_context'])):\n",
        "        # If left context contains only '<start>'\n",
        "        if len(ppd['left_context'][i]) == 1:\n",
        "            lengths.append(i)\n",
        "    lengths.append(len(ppd['left_context']))\n",
        "    compressor = []\n",
        "    compressor.append(range(lengths[0]))\n",
        "    for i in range (1,len(lengths)):\n",
        "        compressor.append(range(lengths[i-1],lengths[i]))\n",
        "    return compressor"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNWYsrPpP0es"
      },
      "source": [
        "comp = compress()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUUEUouCNQmb"
      },
      "source": [
        "# Training Data, Test Data Preparation\n",
        "\n",
        "def prep (train_indices, test_indices):\n",
        "    print (len(train_indices), len(test_indices))\n",
        "\n",
        "    # Ungroup training dataset candidate-words belonging to the same line.\n",
        "    train_ids = []\n",
        "    for i in range(len(train_indices)):\n",
        "        train_ids.extend(comp[train_indices[i]])\n",
        "\n",
        "    # Ungroup testing dataset candidate-words belonging to the same line.\n",
        "    test_ids = []\n",
        "    for i in range(len(test_indices)):\n",
        "        test_ids.extend(comp[test_indices[i]])\n",
        "\n",
        "    # Training Data Preparation\n",
        "    train_left   = []\n",
        "    train_right  = []\n",
        "    train_middle = []\n",
        "    train_labels = []\n",
        "    train_pos_vec= []\n",
        "    train_ner_vec= []\n",
        "    train_empath_vec=[]\n",
        "\n",
        "    for id in train_ids:\n",
        "        train_left.append(keras_left_context[id])\n",
        "        train_right.append(keras_right_context[id])\n",
        "        train_middle.append(keras_middle[id])\n",
        "        train_labels.append(labels[id])\n",
        "        train_pos_vec.append(pos_vec[id])\n",
        "        train_ner_vec.append(ner_vec[id])\n",
        "        train_empath_vec.append(empath_vec[id])\n",
        "\n",
        "    train_left   = np.array(train_left)\n",
        "    train_right  = np.array(train_right)\n",
        "    train_middle = np.array(train_middle)\n",
        "    train_labels = np.array(train_labels)\n",
        "    train_middle = np.expand_dims(train_middle,axis=1)\n",
        "    train_pos_vec= np.array(train_pos_vec)\n",
        "    train_ner_vec= np.array(train_ner_vec)\n",
        "    train_empath_vec= np.array(train_empath_vec)\n",
        "\n",
        "    # Testing Data Preparation\n",
        "    val_left   = []\n",
        "    val_right  = []\n",
        "    val_middle = []\n",
        "    val_labels = []\n",
        "    val_pos_vec= []\n",
        "    val_ner_vec= []\n",
        "    val_empath_vec=[]\n",
        "\n",
        "    for id in test_ids:\n",
        "        val_left.append(keras_left_context[id])\n",
        "        val_right.append(keras_right_context[id])\n",
        "        val_middle.append(keras_middle[id])\n",
        "        val_labels.append(labels[id])\n",
        "        val_pos_vec.append(pos_vec[id])\n",
        "        val_ner_vec.append(ner_vec[id])\n",
        "        val_empath_vec.append(empath_vec[id])\n",
        "\n",
        "    val_left   = np.array(val_left)\n",
        "    val_right  = np.array(val_right)\n",
        "    val_middle = np.array(val_middle)\n",
        "    val_labels = np.array(val_labels)\n",
        "    val_middle = np.expand_dims(val_middle, axis=1)\n",
        "    val_pos_vec=np.array(val_pos_vec)\n",
        "    val_ner_vec=np.array(val_ner_vec)\n",
        "    val_empath_vec=np.array(val_empath_vec)\n",
        "\n",
        "    # Below part only for TD lstm\n",
        "    if mode == 'TD':\t    \n",
        "      train_left = np.concatenate((train_left, train_middle), axis=1)\n",
        "      train_right = np.concatenate((train_middle, train_right), axis=1)\n",
        "      val_left = np.concatenate((val_left, val_middle), axis=1)\n",
        "      val_right = np.concatenate((val_middle, val_right), axis=1)\n",
        "\n",
        "    return(train_left,train_right,train_middle,train_pos_vec,train_ner_vec,train_empath_vec,train_labels,val_left,val_right,val_middle,val_pos_vec,val_ner_vec,val_empath_vec,val_labels)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34X2_lDDA-FB"
      },
      "source": [
        "def de_comp(arr, test_indices):\n",
        "    arr = deque(arr)\n",
        "    fin = []\n",
        "    for i in test_indices:\n",
        "        temp = []\n",
        "        for j in range(len(comp[i])):\n",
        "            temp.append(arr.popleft())\n",
        "        fin.append(temp)\n",
        "    return (fin)    "
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYk7ipoiBF43"
      },
      "source": [
        "def accuracy (pred, labels, test_indices):\n",
        "    pred = pred[0]\n",
        "    num_sent = len(comp)\n",
        "    num_words = len(pred)\n",
        "    threshold = 0\n",
        "    cnt = 0\n",
        "    # Threshold calculation for binary classification problem\n",
        "    for a,b in zip (pred,labels):\n",
        "        if b==1.0:\n",
        "            threshold+=a\n",
        "            cnt+=1\n",
        "    threshold = threshold.item()/cnt\n",
        "\n",
        "    pred_th = []\n",
        "    for x in pred:\n",
        "        if (x<=threshold):\n",
        "            pred_th.append(0)\n",
        "        else :\n",
        "            pred_th.append(1)\n",
        "\n",
        "    pred_th = np.array(pred_th)\n",
        "    print (\"Number of Test sentences : {}\".format(len(test_indices)))\n",
        "    error = pred_th-labels\n",
        "    error_d  = de_comp(error,test_indices)\n",
        "    labels_d = de_comp(labels,test_indices)\n",
        "    pred_d   = de_comp(pred_th,test_indices)\n",
        "    em_cnt = 0\n",
        "    ds_cnt = 0\n",
        "    mic_f1 = 0\n",
        "\n",
        "    for err in error_d:\n",
        "        if (sum(err)==0):\n",
        "           em_cnt += 1\n",
        "        ds_cnt += float(len(err)-sum(np.abs(err)))/len(err)\n",
        "\n",
        "    for lab, pre in zip(labels_d,pred_d):\n",
        "\n",
        "        tp = 0\n",
        "        fp = 0\n",
        "        fn = 0\n",
        "        tn = 0\n",
        "              \n",
        "        for i,j in zip(lab,pre):\n",
        "            if (int(i) == 1)  and (int(j) ==0) :\n",
        "                fn += 1\n",
        "            elif (int(i) == 0)  and (int(j) ==1) :\n",
        "                fp += 1\n",
        "            elif (int(i) == 0)  and (int(j) ==0) :\n",
        "                tn += 1\n",
        "            elif (int(i) == 1) and (int(j) ==1):\n",
        "                tp += 1\n",
        "        try : \n",
        "            mic_f1 += float(2*tp) / (2*tp + fn +fp)\n",
        "        except :\n",
        "            pass\n",
        "\n",
        "    TP=0\n",
        "    TN=0\n",
        "    FP=0\n",
        "    FN=0\n",
        "    for a,b in zip(labels, pred_th):\n",
        "\n",
        "        if int(a)==0 and b==0:\n",
        "            TN+=1\n",
        "        if int(a)==1 and b==1:\n",
        "            TP+=1\n",
        "        if int(a)==0 and b==1:\n",
        "            FP+=1\n",
        "        if int(a)==1 and b==0:\n",
        "            FN+=1 \n",
        "    print (\"TP = {}, TN = {},FP = {}, FN = {}\".format(TP,TN,FP,FN))\n",
        "    F1 = float(2*TP)/(2*TP + FP+ FN)\n",
        "    EM = float(em_cnt)/len(test_indices)\n",
        "    DS = float(ds_cnt)/len(test_indices)\n",
        "    uF1= float(mic_f1)/len(test_indices)\n",
        "    print (\"EM Accuracy : {}\".format(EM))\n",
        "    print (\"DS Accuracy : {}\".format(DS))\n",
        "    print (\"Micro F1    : {}\".format(uF1))\n",
        "    print (\"Macro F1 Score = {}\".format(F1))\n",
        "    return (pred_d, labels_d)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWC-tUwcAJx3"
      },
      "source": [
        "# Tuned-Hyper Parameters\n",
        "embed_size = 1024\n",
        "hidden_size = 32\n",
        "num_epochs=30\n",
        "layer_size = 16\n",
        "batch_size = 64\n",
        "\n",
        "# 'Uni' : Unidirectional LSTM  |  'Bi' : Bidirectional LSTM  | 'TD' : Target-dependent LSTM\n",
        "mode = 'Uni' \n",
        "augmentation = False"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZkaHjZN1IPM"
      },
      "source": [
        "def model(train_l,train_r,train_m,train_pos,train_ner,train_empath,train_labels,test_l,test_r,test_m,test_pos,test_ner,test_empath,test_labels,test_indices):\n",
        "    \n",
        "    x=Input(shape=(78, 300))\n",
        "    y=Input(shape=(78, 300))\n",
        "    z=Input(shape=(1, 300))\n",
        "    z1=Input(shape=([1,34]))\n",
        "    z2=Input(shape=([1,2]))\n",
        "    # z3=Input(shape=([64]))\n",
        "    z4=Input(shape=([194]))\n",
        "\n",
        "    if mode == 'Bi':\n",
        "    \tleft_out=Bidirectional(LSTM(hidden_size//2,return_sequences=False),input_shape=(train_l.shape[1:]))(x)      \n",
        "    \tmiddle = Bidirectional(LSTM(hidden_size//2,return_sequences=False),input_shape=(train_m.shape[1:]))(z)\n",
        "    \tright_out=Bidirectional(LSTM(hidden_size//2,return_sequences=False),input_shape=(train_r.shape[1:]))(y)\n",
        "\n",
        "    else:\n",
        "    \tleft_out  = LSTM(hidden_size,return_sequences=False)(x)\n",
        "    \tmiddle    = LSTM(hidden_size,return_sequences=False)(z)\n",
        "    \tright_out = LSTM(hidden_size,return_sequences=False)(y)\n",
        "\n",
        "    pos_dense=Dense(32,activation='relu')(z1)\n",
        "    ner_dense=Dense(16,activation='relu')(z2)\n",
        "    # liwc_dense=Dense(64,activation='relu')(z3)\n",
        "    empath_dense=Dense(64,activation='relu')(z4)\n",
        "\n",
        "    if mode == 'TD' and augmentation == False :\n",
        "      out=concatenate([left_out,right_out],axis=-1)\n",
        "\n",
        "    if mode == 'TD' and augmentation == True :\n",
        "    \tout=concatenate([left_out,right_out,pos_dense,ner_dense,empath_dense],axis=-1)\n",
        "\n",
        "    if mode != 'TD' and augmentation == False :\n",
        "      out=concatenate([left_out,middle,right_out],axis=-1)\n",
        "\n",
        "    if mode != 'TD' and augmentation == True :\n",
        "    \tout=concatenate([left_out,middle,right_out,pos_dense,ner_dense,empath_dense],axis=-1)\n",
        "\n",
        "    out=Dense(layer_size, activation='relu')(out)\n",
        "    output=Dense(1, activation='sigmoid')(out)\n",
        "    model = Model(inputs=[x,y,z,z1,z2,z4], outputs=output)\n",
        "    model.compile(optimizer=Adam(lr=10e-5),loss='binary_crossentropy',metrics=['accuracy'])\n",
        "    print (\"Starting Epochs\")\n",
        "    for i in range(num_epochs):\n",
        "        model.fit([train_l,train_r,train_m,train_pos,train_ner,train_empath],train_labels,batch_size=batch_size, epochs=1,verbose=0)\n",
        "        print('***************************************************************')\n",
        "        print (\"predicting_ Epoch : {}\".format(i))\n",
        "        pred_val=[]\n",
        "        pred_val.append(model.predict([test_l,test_r,test_m,test_pos,test_ner,test_empath]))\n",
        "        pre_d, lab_d = accuracy (pred_val, test_labels,test_indices)\n",
        "\n",
        "        # with open('Tweets Aug-{}.csv'.format(i), mode='w') as file:\n",
        "        #     file_writer = csv.writer(file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
        "        #     for a,b in zip (pre_d,lab_d):\n",
        "        #         file_writer.writerow([a,b])\n",
        "    return model"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFHCUy5jLV2e"
      },
      "source": [
        "# Dataset division for 3-fold cross validation\n",
        "indices = list(range(len(comp)))\n",
        "np.random.shuffle(indices)\n",
        "bins = []\n",
        "bins.append(indices[:int(0.33*len(indices))])\n",
        "bins.append(indices[int(0.33*len(indices)):int(0.66*len(indices))])\n",
        "bins.append(indices[int(0.66*len(indices)):])"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6hjPEsuN-33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9925d7c-99b9-4783-c40d-9cfff441c7bb"
      },
      "source": [
        "for i in range (3):\n",
        "    print (\"Fold {}\".format(i+1))\n",
        "    print (len(bins[0] + bins[1]),len(bins[2]))\n",
        "    train_left,train_right,train_middle,pos_vec_train,ner_vec_train,empath_vec_train,train_labels,val_left,val_right,val_middle,pos_vec_val,ner_vec_val,empath_vec_val,val_labels = prep (bins[i%3] + bins[(i+1)%3], bins[(i+2)%3])\n",
        "    Sar_model=model(train_left,train_right,train_middle,pos_vec_train,ner_vec_train,empath_vec_train,train_labels,val_left,val_right,val_middle,pos_vec_val,ner_vec_val,empath_vec_val,val_labels,bins[(i+2)%3])\n",
        "    Sar_model.save_weights(\"Bert Tweets Aug.h5\")\n",
        "    print(\"Saved model to disk\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold 1\n",
            "147 77\n",
            "147 77\n",
            "Starting Epochs\n",
            "***************************************************************\n",
            "predicting_ Epoch : 0\n",
            "Number of Test sentences : 77\n",
            "TP = 146, TN = 608,FP = 1236, FN = 87\n",
            "EM Accuracy : 0.0\n",
            "DS Accuracy : 0.3598391159519356\n",
            "Micro F1    : 0.19052550116794253\n",
            "Macro F1 Score = 0.18080495356037152\n",
            "***************************************************************\n",
            "predicting_ Epoch : 1\n",
            "Number of Test sentences : 77\n",
            "TP = 122, TN = 780,FP = 1064, FN = 111\n",
            "EM Accuracy : 0.0\n",
            "DS Accuracy : 0.35609617359965706\n",
            "Micro F1    : 0.1753410166973508\n",
            "Macro F1 Score = 0.1719520789288231\n",
            "***************************************************************\n",
            "predicting_ Epoch : 2\n",
            "Number of Test sentences : 77\n",
            "TP = 129, TN = 960,FP = 884, FN = 104\n",
            "EM Accuracy : 0.0\n",
            "DS Accuracy : 0.43042533417578344\n",
            "Micro F1    : 0.19677281137668906\n",
            "Macro F1 Score = 0.20706260032102727\n",
            "***************************************************************\n",
            "predicting_ Epoch : 3\n",
            "Number of Test sentences : 77\n",
            "TP = 133, TN = 1140,FP = 704, FN = 100\n",
            "EM Accuracy : 0.0\n",
            "DS Accuracy : 0.5204403141125312\n",
            "Micro F1    : 0.2283343171582525\n",
            "Macro F1 Score = 0.2485981308411215\n",
            "***************************************************************\n",
            "predicting_ Epoch : 4\n",
            "Number of Test sentences : 77\n",
            "TP = 127, TN = 1282,FP = 562, FN = 106\n",
            "EM Accuracy : 0.0\n",
            "DS Accuracy : 0.5843271600096169\n",
            "Micro F1    : 0.24773631389629924\n",
            "Macro F1 Score = 0.2754880694143167\n",
            "***************************************************************\n",
            "predicting_ Epoch : 5\n",
            "Number of Test sentences : 77\n",
            "TP = 118, TN = 1476,FP = 368, FN = 115\n",
            "EM Accuracy : 0.09090909090909091\n",
            "DS Accuracy : 0.6970308923468495\n",
            "Micro F1    : 0.2946240310067658\n",
            "Macro F1 Score = 0.3282336578581363\n",
            "***************************************************************\n",
            "predicting_ Epoch : 6\n",
            "Number of Test sentences : 77\n",
            "TP = 112, TN = 1463,FP = 381, FN = 121\n",
            "EM Accuracy : 0.11688311688311688\n",
            "DS Accuracy : 0.6704969693804768\n",
            "Micro F1    : 0.28060126906127586\n",
            "Macro F1 Score = 0.3085399449035813\n",
            "***************************************************************\n",
            "predicting_ Epoch : 7\n",
            "Number of Test sentences : 77\n",
            "TP = 101, TN = 1518,FP = 326, FN = 132\n",
            "EM Accuracy : 0.12987012987012986\n",
            "DS Accuracy : 0.6921161162644616\n",
            "Micro F1    : 0.2817351888347792\n",
            "Macro F1 Score = 0.30606060606060603\n",
            "***************************************************************\n",
            "predicting_ Epoch : 8\n",
            "Number of Test sentences : 77\n",
            "TP = 110, TN = 1427,FP = 417, FN = 123\n",
            "EM Accuracy : 0.14285714285714285\n",
            "DS Accuracy : 0.6765498866005036\n",
            "Micro F1    : 0.2898745838283417\n",
            "Macro F1 Score = 0.2894736842105263\n",
            "***************************************************************\n",
            "predicting_ Epoch : 9\n",
            "Number of Test sentences : 77\n",
            "TP = 91, TN = 1531,FP = 313, FN = 142\n",
            "EM Accuracy : 0.12987012987012986\n",
            "DS Accuracy : 0.7212759967598853\n",
            "Micro F1    : 0.27112499843487387\n",
            "Macro F1 Score = 0.2857142857142857\n",
            "***************************************************************\n",
            "predicting_ Epoch : 10\n",
            "Number of Test sentences : 77\n",
            "TP = 91, TN = 1630,FP = 214, FN = 142\n",
            "EM Accuracy : 0.19480519480519481\n",
            "DS Accuracy : 0.8069497675978319\n",
            "Micro F1    : 0.33508721277302816\n",
            "Macro F1 Score = 0.3382899628252788\n",
            "***************************************************************\n",
            "predicting_ Epoch : 11\n",
            "Number of Test sentences : 77\n",
            "TP = 98, TN = 1583,FP = 261, FN = 135\n",
            "EM Accuracy : 0.09090909090909091\n",
            "DS Accuracy : 0.7575388730941599\n",
            "Micro F1    : 0.3141874026257979\n",
            "Macro F1 Score = 0.3310810810810811\n",
            "***************************************************************\n",
            "predicting_ Epoch : 12\n",
            "Number of Test sentences : 77\n",
            "TP = 97, TN = 1615,FP = 229, FN = 136\n",
            "EM Accuracy : 0.14285714285714285\n",
            "DS Accuracy : 0.7842583044908478\n",
            "Micro F1    : 0.3382920613652479\n",
            "Macro F1 Score = 0.3470483005366726\n",
            "***************************************************************\n",
            "predicting_ Epoch : 13\n",
            "Number of Test sentences : 77\n",
            "TP = 98, TN = 1569,FP = 275, FN = 135\n",
            "EM Accuracy : 0.12987012987012986\n",
            "DS Accuracy : 0.7621304597513594\n",
            "Micro F1    : 0.33155811579724626\n",
            "Macro F1 Score = 0.3234323432343234\n",
            "***************************************************************\n",
            "predicting_ Epoch : 14\n",
            "Number of Test sentences : 77\n",
            "TP = 92, TN = 1637,FP = 207, FN = 141\n",
            "EM Accuracy : 0.19480519480519481\n",
            "DS Accuracy : 0.8179421317246731\n",
            "Micro F1    : 0.3700442230547137\n",
            "Macro F1 Score = 0.3458646616541353\n",
            "***************************************************************\n",
            "predicting_ Epoch : 15\n",
            "Number of Test sentences : 77\n",
            "TP = 97, TN = 1662,FP = 182, FN = 136\n",
            "EM Accuracy : 0.2077922077922078\n",
            "DS Accuracy : 0.8274811877295515\n",
            "Micro F1    : 0.3938362465361781\n",
            "Macro F1 Score = 0.37890625\n",
            "***************************************************************\n",
            "predicting_ Epoch : 16\n",
            "Number of Test sentences : 77\n",
            "TP = 94, TN = 1681,FP = 163, FN = 139\n",
            "EM Accuracy : 0.2077922077922078\n",
            "DS Accuracy : 0.8361207269542794\n",
            "Micro F1    : 0.3983139774463002\n",
            "Macro F1 Score = 0.3836734693877551\n",
            "***************************************************************\n",
            "predicting_ Epoch : 17\n",
            "Number of Test sentences : 77\n",
            "TP = 92, TN = 1703,FP = 141, FN = 141\n",
            "EM Accuracy : 0.22077922077922077\n",
            "DS Accuracy : 0.849246698226984\n",
            "Micro F1    : 0.4035957366852787\n",
            "Macro F1 Score = 0.3948497854077253\n",
            "***************************************************************\n",
            "predicting_ Epoch : 18\n",
            "Number of Test sentences : 77\n",
            "TP = 91, TN = 1707,FP = 137, FN = 142\n",
            "EM Accuracy : 0.2077922077922078\n",
            "DS Accuracy : 0.8484406008373205\n",
            "Micro F1    : 0.404440209293251\n",
            "Macro F1 Score = 0.3947939262472885\n",
            "***************************************************************\n",
            "predicting_ Epoch : 19\n",
            "Number of Test sentences : 77\n",
            "TP = 98, TN = 1676,FP = 168, FN = 135\n",
            "EM Accuracy : 0.18181818181818182\n",
            "DS Accuracy : 0.8330686356491042\n",
            "Micro F1    : 0.4047910576288732\n",
            "Macro F1 Score = 0.3927855711422846\n",
            "***************************************************************\n",
            "predicting_ Epoch : 20\n",
            "Number of Test sentences : 77\n",
            "TP = 98, TN = 1692,FP = 152, FN = 135\n",
            "EM Accuracy : 0.19480519480519481\n",
            "DS Accuracy : 0.8361140009747108\n",
            "Micro F1    : 0.4159136640681412\n",
            "Macro F1 Score = 0.4057971014492754\n",
            "***************************************************************\n",
            "predicting_ Epoch : 21\n",
            "Number of Test sentences : 77\n",
            "TP = 93, TN = 1719,FP = 125, FN = 140\n",
            "EM Accuracy : 0.2727272727272727\n",
            "DS Accuracy : 0.8597641660289009\n",
            "Micro F1    : 0.4299880949915127\n",
            "Macro F1 Score = 0.4124168514412417\n",
            "***************************************************************\n",
            "predicting_ Epoch : 22\n",
            "Number of Test sentences : 77\n",
            "TP = 96, TN = 1699,FP = 145, FN = 137\n",
            "EM Accuracy : 0.22077922077922077\n",
            "DS Accuracy : 0.8473344272749505\n",
            "Micro F1    : 0.41398075229244063\n",
            "Macro F1 Score = 0.4050632911392405\n",
            "***************************************************************\n",
            "predicting_ Epoch : 23\n",
            "Number of Test sentences : 77\n",
            "TP = 98, TN = 1682,FP = 162, FN = 135\n",
            "EM Accuracy : 0.23376623376623376\n",
            "DS Accuracy : 0.8465911487888822\n",
            "Micro F1    : 0.4222961752484088\n",
            "Macro F1 Score = 0.3975659229208925\n",
            "***************************************************************\n",
            "predicting_ Epoch : 24\n",
            "Number of Test sentences : 77\n",
            "TP = 101, TN = 1703,FP = 141, FN = 132\n",
            "EM Accuracy : 0.2077922077922078\n",
            "DS Accuracy : 0.8479802277317964\n",
            "Micro F1    : 0.4215188342766647\n",
            "Macro F1 Score = 0.42526315789473684\n",
            "***************************************************************\n",
            "predicting_ Epoch : 25\n",
            "Number of Test sentences : 77\n",
            "TP = 94, TN = 1711,FP = 133, FN = 139\n",
            "EM Accuracy : 0.22077922077922077\n",
            "DS Accuracy : 0.8530302262224915\n",
            "Micro F1    : 0.41722783937411423\n",
            "Macro F1 Score = 0.40869565217391307\n",
            "***************************************************************\n",
            "predicting_ Epoch : 26\n",
            "Number of Test sentences : 77\n",
            "TP = 89, TN = 1697,FP = 147, FN = 144\n",
            "EM Accuracy : 0.23376623376623376\n",
            "DS Accuracy : 0.8516889189714048\n",
            "Micro F1    : 0.41316424890344583\n",
            "Macro F1 Score = 0.3795309168443497\n",
            "***************************************************************\n",
            "predicting_ Epoch : 27\n",
            "Number of Test sentences : 77\n",
            "TP = 88, TN = 1706,FP = 138, FN = 145\n",
            "EM Accuracy : 0.2727272727272727\n",
            "DS Accuracy : 0.8540624090573089\n",
            "Micro F1    : 0.4127939881186635\n",
            "Macro F1 Score = 0.38344226579520696\n",
            "***************************************************************\n",
            "predicting_ Epoch : 28\n",
            "Number of Test sentences : 77\n",
            "TP = 82, TN = 1731,FP = 113, FN = 151\n",
            "EM Accuracy : 0.24675324675324675\n",
            "DS Accuracy : 0.8665842430168247\n",
            "Micro F1    : 0.40924971811144467\n",
            "Macro F1 Score = 0.38317757009345793\n",
            "***************************************************************\n",
            "predicting_ Epoch : 29\n",
            "Number of Test sentences : 77\n",
            "TP = 85, TN = 1715,FP = 129, FN = 148\n",
            "EM Accuracy : 0.23376623376623376\n",
            "DS Accuracy : 0.85772413711992\n",
            "Micro F1    : 0.3978185329518208\n",
            "Macro F1 Score = 0.38031319910514544\n",
            "Saved model to disk\n",
            "Fold 2\n",
            "147 77\n",
            "151 73\n",
            "Starting Epochs\n",
            "***************************************************************\n",
            "predicting_ Epoch : 0\n",
            "Number of Test sentences : 73\n",
            "TP = 159, TN = 986,FP = 816, FN = 92\n",
            "EM Accuracy : 0.0273972602739726\n",
            "DS Accuracy : 0.551492615785077\n",
            "Micro F1    : 0.2465349069655429\n",
            "Macro F1 Score = 0.25938009787928223\n",
            "***************************************************************\n",
            "predicting_ Epoch : 1\n",
            "Number of Test sentences : 73\n",
            "TP = 141, TN = 1013,FP = 789, FN = 110\n",
            "EM Accuracy : 0.0273972602739726\n",
            "DS Accuracy : 0.41869705765214393\n",
            "Micro F1    : 0.2058650015071497\n",
            "Macro F1 Score = 0.23878069432684165\n",
            "***************************************************************\n",
            "predicting_ Epoch : 2\n",
            "Number of Test sentences : 73\n",
            "TP = 120, TN = 1289,FP = 513, FN = 131\n",
            "EM Accuracy : 0.0410958904109589\n",
            "DS Accuracy : 0.523416181701495\n",
            "Micro F1    : 0.20058322210863988\n",
            "Macro F1 Score = 0.27149321266968324\n",
            "***************************************************************\n",
            "predicting_ Epoch : 3\n",
            "Number of Test sentences : 73\n",
            "TP = 115, TN = 1353,FP = 449, FN = 136\n",
            "EM Accuracy : 0.0273972602739726\n",
            "DS Accuracy : 0.55456677696109\n",
            "Micro F1    : 0.2280076170585872\n",
            "Macro F1 Score = 0.2822085889570552\n",
            "***************************************************************\n",
            "predicting_ Epoch : 4\n",
            "Number of Test sentences : 73\n",
            "TP = 113, TN = 1399,FP = 403, FN = 138\n",
            "EM Accuracy : 0.0273972602739726\n",
            "DS Accuracy : 0.5794865622074514\n",
            "Micro F1    : 0.23884367602903073\n",
            "Macro F1 Score = 0.29465449804432853\n",
            "***************************************************************\n",
            "predicting_ Epoch : 5\n",
            "Number of Test sentences : 73\n",
            "TP = 109, TN = 1407,FP = 395, FN = 142\n",
            "EM Accuracy : 0.0410958904109589\n",
            "DS Accuracy : 0.5829535073816509\n",
            "Micro F1    : 0.2533379502016849\n",
            "Macro F1 Score = 0.28874172185430463\n",
            "***************************************************************\n",
            "predicting_ Epoch : 6\n",
            "Number of Test sentences : 73\n",
            "TP = 111, TN = 1479,FP = 323, FN = 140\n",
            "EM Accuracy : 0.0547945205479452\n",
            "DS Accuracy : 0.6343804080043398\n",
            "Micro F1    : 0.2952669543725143\n",
            "Macro F1 Score = 0.32408759124087594\n",
            "***************************************************************\n",
            "predicting_ Epoch : 7\n",
            "Number of Test sentences : 73\n",
            "TP = 111, TN = 1530,FP = 272, FN = 140\n",
            "EM Accuracy : 0.0821917808219178\n",
            "DS Accuracy : 0.6940418126988198\n",
            "Micro F1    : 0.3274741595917218\n",
            "Macro F1 Score = 0.3501577287066246\n",
            "***************************************************************\n",
            "predicting_ Epoch : 8\n",
            "Number of Test sentences : 73\n",
            "TP = 104, TN = 1576,FP = 226, FN = 147\n",
            "EM Accuracy : 0.0821917808219178\n",
            "DS Accuracy : 0.7297131472411313\n",
            "Micro F1    : 0.34727703355825834\n",
            "Macro F1 Score = 0.35800344234079173\n",
            "***************************************************************\n",
            "predicting_ Epoch : 9\n",
            "Number of Test sentences : 73\n",
            "TP = 97, TN = 1629,FP = 173, FN = 154\n",
            "EM Accuracy : 0.1780821917808219\n",
            "DS Accuracy : 0.7842830763953273\n",
            "Micro F1    : 0.36831833221841287\n",
            "Macro F1 Score = 0.3723608445297505\n",
            "***************************************************************\n",
            "predicting_ Epoch : 10\n",
            "Number of Test sentences : 73\n",
            "TP = 92, TN = 1646,FP = 156, FN = 159\n",
            "EM Accuracy : 0.2191780821917808\n",
            "DS Accuracy : 0.798857686828649\n",
            "Micro F1    : 0.38767454007180036\n",
            "Macro F1 Score = 0.3687374749498998\n",
            "***************************************************************\n",
            "predicting_ Epoch : 11\n",
            "Number of Test sentences : 73\n",
            "TP = 94, TN = 1651,FP = 151, FN = 157\n",
            "EM Accuracy : 0.2054794520547945\n",
            "DS Accuracy : 0.8030662327224964\n",
            "Micro F1    : 0.3920977424402081\n",
            "Macro F1 Score = 0.3790322580645161\n",
            "***************************************************************\n",
            "predicting_ Epoch : 12\n",
            "Number of Test sentences : 73\n",
            "TP = 96, TN = 1643,FP = 159, FN = 155\n",
            "EM Accuracy : 0.2191780821917808\n",
            "DS Accuracy : 0.8063696388351915\n",
            "Micro F1    : 0.3932594802457816\n",
            "Macro F1 Score = 0.3794466403162055\n",
            "***************************************************************\n",
            "predicting_ Epoch : 13\n",
            "Number of Test sentences : 73\n",
            "TP = 97, TN = 1637,FP = 165, FN = 154\n",
            "EM Accuracy : 0.1643835616438356\n",
            "DS Accuracy : 0.8062901118801027\n",
            "Micro F1    : 0.3976063510310086\n",
            "Macro F1 Score = 0.37816764132553604\n",
            "***************************************************************\n",
            "predicting_ Epoch : 14\n",
            "Number of Test sentences : 73\n",
            "TP = 100, TN = 1637,FP = 165, FN = 151\n",
            "EM Accuracy : 0.2054794520547945\n",
            "DS Accuracy : 0.8114372807151782\n",
            "Micro F1    : 0.4096716449456176\n",
            "Macro F1 Score = 0.3875968992248062\n",
            "***************************************************************\n",
            "predicting_ Epoch : 15\n",
            "Number of Test sentences : 73\n",
            "TP = 95, TN = 1640,FP = 162, FN = 156\n",
            "EM Accuracy : 0.2191780821917808\n",
            "DS Accuracy : 0.8168963451234883\n",
            "Micro F1    : 0.4049225127992251\n",
            "Macro F1 Score = 0.37401574803149606\n",
            "***************************************************************\n",
            "predicting_ Epoch : 16\n",
            "Number of Test sentences : 73\n",
            "TP = 105, TN = 1619,FP = 183, FN = 146\n",
            "EM Accuracy : 0.1917808219178082\n",
            "DS Accuracy : 0.8059761078936745\n",
            "Micro F1    : 0.40354498219123514\n",
            "Macro F1 Score = 0.38961038961038963\n",
            "***************************************************************\n",
            "predicting_ Epoch : 17\n",
            "Number of Test sentences : 73\n",
            "TP = 106, TN = 1620,FP = 182, FN = 145\n",
            "EM Accuracy : 0.1506849315068493\n",
            "DS Accuracy : 0.8124630634460873\n",
            "Micro F1    : 0.41149748794793123\n",
            "Macro F1 Score = 0.39332096474953615\n",
            "***************************************************************\n",
            "predicting_ Epoch : 18\n",
            "Number of Test sentences : 73\n",
            "TP = 107, TN = 1618,FP = 184, FN = 144\n",
            "EM Accuracy : 0.1232876712328767\n",
            "DS Accuracy : 0.8143556458752554\n",
            "Micro F1    : 0.4192228228690759\n",
            "Macro F1 Score = 0.3948339483394834\n",
            "***************************************************************\n",
            "predicting_ Epoch : 19\n",
            "Number of Test sentences : 73\n",
            "TP = 102, TN = 1625,FP = 177, FN = 149\n",
            "EM Accuracy : 0.1506849315068493\n",
            "DS Accuracy : 0.8161574282799896\n",
            "Micro F1    : 0.3984524607812279\n",
            "Macro F1 Score = 0.3849056603773585\n",
            "***************************************************************\n",
            "predicting_ Epoch : 20\n",
            "Number of Test sentences : 73\n",
            "TP = 104, TN = 1628,FP = 174, FN = 147\n",
            "EM Accuracy : 0.1506849315068493\n",
            "DS Accuracy : 0.8188255984499623\n",
            "Micro F1    : 0.4059265742935534\n",
            "Macro F1 Score = 0.3931947069943289\n",
            "***************************************************************\n",
            "predicting_ Epoch : 21\n",
            "Number of Test sentences : 73\n",
            "TP = 104, TN = 1636,FP = 166, FN = 147\n",
            "EM Accuracy : 0.1506849315068493\n",
            "DS Accuracy : 0.8216398944834363\n",
            "Micro F1    : 0.4048099841358674\n",
            "Macro F1 Score = 0.39923224568138194\n",
            "***************************************************************\n",
            "predicting_ Epoch : 22\n",
            "Number of Test sentences : 73\n",
            "TP = 98, TN = 1635,FP = 167, FN = 153\n",
            "EM Accuracy : 0.1780821917808219\n",
            "DS Accuracy : 0.8187559997191112\n",
            "Micro F1    : 0.39726577796152424\n",
            "Macro F1 Score = 0.3798449612403101\n",
            "***************************************************************\n",
            "predicting_ Epoch : 23\n",
            "Number of Test sentences : 73\n",
            "TP = 109, TN = 1622,FP = 180, FN = 142\n",
            "EM Accuracy : 0.1643835616438356\n",
            "DS Accuracy : 0.8222514895691077\n",
            "Micro F1    : 0.43471200753104144\n",
            "Macro F1 Score = 0.40370370370370373\n",
            "***************************************************************\n",
            "predicting_ Epoch : 24\n",
            "Number of Test sentences : 73\n",
            "TP = 108, TN = 1627,FP = 175, FN = 143\n",
            "EM Accuracy : 0.1780821917808219\n",
            "DS Accuracy : 0.8214026519851215\n",
            "Micro F1    : 0.42994262468754685\n",
            "Macro F1 Score = 0.4044943820224719\n",
            "***************************************************************\n",
            "predicting_ Epoch : 25\n",
            "Number of Test sentences : 73\n",
            "TP = 95, TN = 1644,FP = 158, FN = 156\n",
            "EM Accuracy : 0.2328767123287671\n",
            "DS Accuracy : 0.8263547555287787\n",
            "Micro F1    : 0.3976883846746861\n",
            "Macro F1 Score = 0.376984126984127\n",
            "***************************************************************\n",
            "predicting_ Epoch : 26\n",
            "Number of Test sentences : 73\n",
            "TP = 108, TN = 1622,FP = 180, FN = 143\n",
            "EM Accuracy : 0.2054794520547945\n",
            "DS Accuracy : 0.8224618169028295\n",
            "Micro F1    : 0.4323051046285924\n",
            "Macro F1 Score = 0.4007421150278293\n",
            "***************************************************************\n",
            "predicting_ Epoch : 27\n",
            "Number of Test sentences : 73\n",
            "TP = 103, TN = 1644,FP = 158, FN = 148\n",
            "EM Accuracy : 0.2191780821917808\n",
            "DS Accuracy : 0.8299482964602544\n",
            "Micro F1    : 0.414627107651621\n",
            "Macro F1 Score = 0.40234375\n",
            "***************************************************************\n",
            "predicting_ Epoch : 28\n",
            "Number of Test sentences : 73\n",
            "TP = 106, TN = 1646,FP = 156, FN = 145\n",
            "EM Accuracy : 0.1917808219178082\n",
            "DS Accuracy : 0.8303711655550151\n",
            "Micro F1    : 0.43440738035292514\n",
            "Macro F1 Score = 0.41325536062378165\n",
            "***************************************************************\n",
            "predicting_ Epoch : 29\n",
            "Number of Test sentences : 73\n",
            "TP = 108, TN = 1631,FP = 171, FN = 143\n",
            "EM Accuracy : 0.1780821917808219\n",
            "DS Accuracy : 0.8234461957095235\n",
            "Micro F1    : 0.4356272058372343\n",
            "Macro F1 Score = 0.4075471698113208\n",
            "Saved model to disk\n",
            "Fold 3\n",
            "147 77\n",
            "150 74\n",
            "Starting Epochs\n",
            "***************************************************************\n",
            "predicting_ Epoch : 0\n",
            "Number of Test sentences : 74\n",
            "TP = 124, TN = 698,FP = 904, FN = 123\n",
            "EM Accuracy : 0.04054054054054054\n",
            "DS Accuracy : 0.46034380758743987\n",
            "Micro F1    : 0.18493648028115034\n",
            "Macro F1 Score = 0.19450980392156864\n",
            "***************************************************************\n",
            "predicting_ Epoch : 1\n",
            "Number of Test sentences : 74\n",
            "TP = 122, TN = 918,FP = 684, FN = 125\n",
            "EM Accuracy : 0.013513513513513514\n",
            "DS Accuracy : 0.4277953826857752\n",
            "Micro F1    : 0.212763824957639\n",
            "Macro F1 Score = 0.23171889838556506\n",
            "***************************************************************\n",
            "predicting_ Epoch : 2\n",
            "Number of Test sentences : 74\n",
            "TP = 123, TN = 1072,FP = 530, FN = 124\n",
            "EM Accuracy : 0.013513513513513514\n",
            "DS Accuracy : 0.541773269019428\n",
            "Micro F1    : 0.24396126899996864\n",
            "Macro F1 Score = 0.2733333333333333\n",
            "***************************************************************\n",
            "predicting_ Epoch : 3\n",
            "Number of Test sentences : 74\n",
            "TP = 109, TN = 1249,FP = 353, FN = 138\n",
            "EM Accuracy : 0.06756756756756757\n",
            "DS Accuracy : 0.6300210138666221\n",
            "Micro F1    : 0.27918642918642905\n",
            "Macro F1 Score = 0.307475317348378\n",
            "***************************************************************\n",
            "predicting_ Epoch : 4\n",
            "Number of Test sentences : 74\n",
            "TP = 96, TN = 1243,FP = 359, FN = 151\n",
            "EM Accuracy : 0.02702702702702703\n",
            "DS Accuracy : 0.6272434185046364\n",
            "Micro F1    : 0.25380243100831335\n",
            "Macro F1 Score = 0.27350427350427353\n",
            "***************************************************************\n",
            "predicting_ Epoch : 5\n",
            "Number of Test sentences : 74\n",
            "TP = 94, TN = 1266,FP = 336, FN = 153\n",
            "EM Accuracy : 0.08108108108108109\n",
            "DS Accuracy : 0.6468122127309217\n",
            "Micro F1    : 0.258977173683056\n",
            "Macro F1 Score = 0.2776957163958641\n",
            "***************************************************************\n",
            "predicting_ Epoch : 6\n",
            "Number of Test sentences : 74\n",
            "TP = 94, TN = 1278,FP = 324, FN = 153\n",
            "EM Accuracy : 0.05405405405405406\n",
            "DS Accuracy : 0.6529246862305425\n",
            "Micro F1    : 0.2553686950745774\n",
            "Macro F1 Score = 0.28270676691729324\n",
            "***************************************************************\n",
            "predicting_ Epoch : 7\n",
            "Number of Test sentences : 74\n",
            "TP = 93, TN = 1323,FP = 279, FN = 154\n",
            "EM Accuracy : 0.12162162162162163\n",
            "DS Accuracy : 0.6841921674716236\n",
            "Micro F1    : 0.2839983060571295\n",
            "Macro F1 Score = 0.30048465266558966\n",
            "***************************************************************\n",
            "predicting_ Epoch : 8\n",
            "Number of Test sentences : 74\n",
            "TP = 96, TN = 1342,FP = 260, FN = 151\n",
            "EM Accuracy : 0.06756756756756757\n",
            "DS Accuracy : 0.6924171047484087\n",
            "Micro F1    : 0.2850379218026276\n",
            "Macro F1 Score = 0.31840796019900497\n",
            "***************************************************************\n",
            "predicting_ Epoch : 9\n",
            "Number of Test sentences : 74\n",
            "TP = 102, TN = 1385,FP = 217, FN = 145\n",
            "EM Accuracy : 0.10810810810810811\n",
            "DS Accuracy : 0.7308207372754981\n",
            "Micro F1    : 0.32513927734515974\n",
            "Macro F1 Score = 0.36042402826855124\n",
            "***************************************************************\n",
            "predicting_ Epoch : 10\n",
            "Number of Test sentences : 74\n",
            "TP = 100, TN = 1405,FP = 197, FN = 147\n",
            "EM Accuracy : 0.14864864864864866\n",
            "DS Accuracy : 0.759429640969496\n",
            "Micro F1    : 0.351944601944602\n",
            "Macro F1 Score = 0.36764705882352944\n",
            "***************************************************************\n",
            "predicting_ Epoch : 11\n",
            "Number of Test sentences : 74\n",
            "TP = 100, TN = 1428,FP = 174, FN = 147\n",
            "EM Accuracy : 0.14864864864864866\n",
            "DS Accuracy : 0.777014440970075\n",
            "Micro F1    : 0.3656705531705532\n",
            "Macro F1 Score = 0.3838771593090211\n",
            "***************************************************************\n",
            "predicting_ Epoch : 12\n",
            "Number of Test sentences : 74\n",
            "TP = 94, TN = 1444,FP = 158, FN = 153\n",
            "EM Accuracy : 0.14864864864864866\n",
            "DS Accuracy : 0.7839664063000625\n",
            "Micro F1    : 0.3499935874935875\n",
            "Macro F1 Score = 0.37675350701402804\n",
            "***************************************************************\n",
            "predicting_ Epoch : 13\n",
            "Number of Test sentences : 74\n",
            "TP = 89, TN = 1465,FP = 137, FN = 158\n",
            "EM Accuracy : 0.14864864864864866\n",
            "DS Accuracy : 0.799187634548291\n",
            "Micro F1    : 0.35123067623067633\n",
            "Macro F1 Score = 0.3763213530655391\n",
            "***************************************************************\n",
            "predicting_ Epoch : 14\n",
            "Number of Test sentences : 74\n",
            "TP = 83, TN = 1488,FP = 114, FN = 164\n",
            "EM Accuracy : 0.1891891891891892\n",
            "DS Accuracy : 0.8187026030028274\n",
            "Micro F1    : 0.3416554916554917\n",
            "Macro F1 Score = 0.3738738738738739\n",
            "***************************************************************\n",
            "predicting_ Epoch : 15\n",
            "Number of Test sentences : 74\n",
            "TP = 79, TN = 1498,FP = 104, FN = 168\n",
            "EM Accuracy : 0.1891891891891892\n",
            "DS Accuracy : 0.82499777898493\n",
            "Micro F1    : 0.3418632418632419\n",
            "Macro F1 Score = 0.3674418604651163\n",
            "***************************************************************\n",
            "predicting_ Epoch : 16\n",
            "Number of Test sentences : 74\n",
            "TP = 80, TN = 1480,FP = 122, FN = 167\n",
            "EM Accuracy : 0.22972972972972974\n",
            "DS Accuracy : 0.8109742640223385\n",
            "Micro F1    : 0.32182944682944686\n",
            "Macro F1 Score = 0.35634743875278396\n",
            "***************************************************************\n",
            "predicting_ Epoch : 17\n",
            "Number of Test sentences : 74\n",
            "TP = 80, TN = 1475,FP = 127, FN = 167\n",
            "EM Accuracy : 0.20270270270270271\n",
            "DS Accuracy : 0.8084280066727544\n",
            "Micro F1    : 0.3160489285489286\n",
            "Macro F1 Score = 0.3524229074889868\n",
            "***************************************************************\n",
            "predicting_ Epoch : 18\n",
            "Number of Test sentences : 74\n",
            "TP = 81, TN = 1495,FP = 107, FN = 166\n",
            "EM Accuracy : 0.16216216216216217\n",
            "DS Accuracy : 0.828816053286692\n",
            "Micro F1    : 0.34687137187137196\n",
            "Macro F1 Score = 0.3724137931034483\n",
            "***************************************************************\n",
            "predicting_ Epoch : 19\n",
            "Number of Test sentences : 74\n",
            "TP = 82, TN = 1493,FP = 109, FN = 165\n",
            "EM Accuracy : 0.14864864864864866\n",
            "DS Accuracy : 0.8265879523125875\n",
            "Micro F1    : 0.3473430473430474\n",
            "Macro F1 Score = 0.3744292237442922\n",
            "***************************************************************\n",
            "predicting_ Epoch : 20\n",
            "Number of Test sentences : 74\n",
            "TP = 81, TN = 1492,FP = 110, FN = 166\n",
            "EM Accuracy : 0.17567567567567569\n",
            "DS Accuracy : 0.8216963973607316\n",
            "Micro F1    : 0.34179724179724186\n",
            "Macro F1 Score = 0.3698630136986301\n",
            "***************************************************************\n",
            "predicting_ Epoch : 21\n",
            "Number of Test sentences : 74\n",
            "TP = 81, TN = 1481,FP = 121, FN = 166\n",
            "EM Accuracy : 0.22972972972972974\n",
            "DS Accuracy : 0.8153659380472389\n",
            "Micro F1    : 0.3360632610632612\n",
            "Macro F1 Score = 0.36080178173719374\n",
            "***************************************************************\n",
            "predicting_ Epoch : 22\n",
            "Number of Test sentences : 74\n",
            "TP = 82, TN = 1482,FP = 120, FN = 165\n",
            "EM Accuracy : 0.20270270270270271\n",
            "DS Accuracy : 0.8185427281508372\n",
            "Micro F1    : 0.3316006816006817\n",
            "Macro F1 Score = 0.36525612472160357\n",
            "***************************************************************\n",
            "predicting_ Epoch : 23\n",
            "Number of Test sentences : 74\n",
            "TP = 84, TN = 1495,FP = 107, FN = 163\n",
            "EM Accuracy : 0.21621621621621623\n",
            "DS Accuracy : 0.826897369369763\n",
            "Micro F1    : 0.35060150060150064\n",
            "Macro F1 Score = 0.3835616438356164\n",
            "***************************************************************\n",
            "predicting_ Epoch : 24\n",
            "Number of Test sentences : 74\n",
            "TP = 84, TN = 1481,FP = 121, FN = 163\n",
            "EM Accuracy : 0.20270270270270271\n",
            "DS Accuracy : 0.822616609657884\n",
            "Micro F1    : 0.33889336242277424\n",
            "Macro F1 Score = 0.37168141592920356\n",
            "***************************************************************\n",
            "predicting_ Epoch : 25\n",
            "Number of Test sentences : 74\n",
            "TP = 83, TN = 1488,FP = 114, FN = 164\n",
            "EM Accuracy : 0.20270270270270271\n",
            "DS Accuracy : 0.8245483936412592\n",
            "Micro F1    : 0.34453179306120485\n",
            "Macro F1 Score = 0.3738738738738739\n",
            "***************************************************************\n",
            "predicting_ Epoch : 26\n",
            "Number of Test sentences : 74\n",
            "TP = 85, TN = 1488,FP = 114, FN = 162\n",
            "EM Accuracy : 0.20270270270270271\n",
            "DS Accuracy : 0.826205341119584\n",
            "Micro F1    : 0.34963524816465996\n",
            "Macro F1 Score = 0.3811659192825112\n",
            "***************************************************************\n",
            "predicting_ Epoch : 27\n",
            "Number of Test sentences : 74\n",
            "TP = 84, TN = 1486,FP = 116, FN = 163\n",
            "EM Accuracy : 0.24324324324324326\n",
            "DS Accuracy : 0.8256834584355397\n",
            "Micro F1    : 0.33567030919972096\n",
            "Macro F1 Score = 0.37583892617449666\n",
            "***************************************************************\n",
            "predicting_ Epoch : 28\n",
            "Number of Test sentences : 74\n",
            "TP = 84, TN = 1478,FP = 124, FN = 163\n",
            "EM Accuracy : 0.17567567567567569\n",
            "DS Accuracy : 0.8186962101800683\n",
            "Micro F1    : 0.34080507683448863\n",
            "Macro F1 Score = 0.36923076923076925\n",
            "***************************************************************\n",
            "predicting_ Epoch : 29\n",
            "Number of Test sentences : 74\n",
            "TP = 86, TN = 1466,FP = 136, FN = 161\n",
            "EM Accuracy : 0.20270270270270271\n",
            "DS Accuracy : 0.813383914169967\n",
            "Micro F1    : 0.33985054971897083\n",
            "Macro F1 Score = 0.36673773987206826\n",
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIoThaMgooE9"
      },
      "source": [
        ""
      ],
      "execution_count": 28,
      "outputs": []
    }
  ]
}